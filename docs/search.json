[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time series Analysis",
    "section": "",
    "text": "What is a Time Series? A time series is any sequence of measurements taken at regular, equally spaced intervals—seconds, minutes, hours, days, months, quarters, or years. Common examples include weather (daily temperature or rainfall), financial markets (daily stock prices or returns), industry indicators (monthly production or sales), electricity demand, traffic counts, and hospital admissions. In time-series analysis we study how these values evolve: their level, trend, seasonal or calendar patterns (e.g., weekdays vs. weekends, holiday effects), cycles, and anomalies. Typical goals are to describe behavior clearly, forecast future values, and quantify the impact of events or policies.\nBecause observations are ordered in time, nearby points tend to be correlated (autocorrelation). This violates the independent-and-identically-distributed assumption behind many standard statistical methods, so naïve cross-sectional tools often mislead. Time-series work must explicitly handle dependence, trend, and seasonality—for example by differencing, seasonal adjustment, and models that use lagged values and errors (e.g., ARIMA/SARIMA, ARIMAX/SARIMAX with external drivers, VAR for multiple series, state-space/ETS, or GARCH when volatility changes over time). Analysts also watch for structural breaks (e.g., policy shifts, COVID), outliers, and missing periods, and they evaluate models with time-aware validation (rolling or blocked splits) rather than random shuffles."
  },
  {
    "objectID": "data_source/data_source.html",
    "href": "data_source/data_source.html",
    "title": "DATA SOURCES",
    "section": "",
    "text": "Data source 1: Yield Curve\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese datasets contain yield curve information for both the United States and Korea. Yield curves represent benchmark borrowing costs across short- and long-term maturities. The difference between long- and short-term yields (“the slope”) reflects market expectations about growth and inflation. The U.S. yield curve will be used primarily to capture U.S. economic conditions, while the Korean yield curve will measure how U.S. rate movements influence Korean bonds. The analysis focuses on the spread between 3-year (short-term) and 10-year (long-term) maturities.\nUS yield curve\nkorea yield curve\n\n\nData source 2: FX spot rate data\n\nThis dataset records the daily exchange rate of the Korean Won (KRW) against the U.S. Dollar (USD). The FX rate is central to understanding the U.S. dollar’s influence on Korea’s financial markets. It allows the detection of turning points, trend shifts, and day-to-day volatility, helping to evaluate how U.S. rate shocks and dollar movements transmit into the Korean currency market.\nKorean won(KRW) data\n\n\nData source 3: Yahoo finance\n\nYahoo Finance provides accessible and reliable financial market data. In this project, it is used to obtain stock market indices such as the KOSPI—the main benchmark for Korean equities,U.S. Dollar Index (DXY) and S&P500 index. These data support analyses linking stock performance and currency strength to U.S. interest rate movements. For this project yfinance via python will be used to access dataset and store to my folder.\nyahoo finance\n\nKOSPI index yfinance code\n\n\nCode\nimport yfinance as yf\nimport pandas as pd\n\nticker = \"^KS11\"\ndata = yf.download(ticker, start=\"1990-01-02\", end=None, interval=\"1d\", progress=False)\n#data.to_csv(\"kospi.csv\")\n\n\n\n\nUSD index yfinance code\n\n\nCode\nimport yfinance as yf\nimport pandas as pd\n\nticker = \"DX-Y.NYB\"\ndata = yf.download(ticker, start=\"1981-04-13\", end=None, interval=\"1d\", progress=False)\n\n#data.to_csv(\"usd_index.csv\")\n\n\n\n\nS&P500 index yfinance code\n\n\nCode\nimport yfinance as yf\nimport pandas as pd\nsp500 = yf.download(\"^GSPC\", start=\"1990-01-02\")\n#sp500.to_csv(\"sp500.csv\")\n\n\n\n\n\nData source 4: Korea import & export data\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis dataset reports Korea’s imports and exports with the United States, measured in thousands of U.S. dollars over time. Since Korea’s economy is heavily export-oriented, t rade data are crucial for assessing how U.S. economic developments—through growth momentum, dollar fluctuations, and rate differentials—affect Korea’s trade performance. This dataset supports the examination of transmission channels between U.S. shocks and Korea’s real economy.\ntrade data\n\n\nData source 5: korean housing data\n\nThis dataset provides the residential property price index for Korea, specifically the Seoul metropolitan area. Given that the housing market represents one of Korea’s largest sectors, changes in property prices and transactions are key indicators of domestic financial conditions. This data enables analysis of how U.S. economic conditions and interest rate changes affect Korea’s housing affordability, financing costs, and overall market activity.\nhousing data\n\n\nData source 6 : FRED effective rate\n\nThis dataset provides the Effective Federal Funds Rate (EFFR) from the Federal Reserve Economic Data (FRED). The effective rate reflects the average interest rate at which depository institutions lend balances to each other overnight and serves as the key indicator of U.S. monetary policy stance. In this project, the FRED rate data represent the foundation of U.S. policy movements, used to identify tightening or easing cycles, measure interest-rate shocks, and analyze how U.S. monetary changes transmit to Korean financial markets, including bond yields, FX, and equity valuations.\nFRED rate\n\n\nDate source 7: Bank of Korea base rate\n\nThis dataset contains the Bank of Korea (BoK) Base Rate, which is the main policy rate set by the BoK’s Monetary Policy Board. The base rate determines short-term money market conditions and anchors borrowing and lending rates across Korea’s financial system. In this project, the BoK rate is used to evaluate domestic monetary policy reactions to external U.S. rate movements. Comparing shifts in the BoK base rate with changes in the FRED effective rate allows identification of synchronization or divergence between the two central banks’ policies and their effects on Korea’s yield curve, currency, and real economy.\nBOK rate"
  },
  {
    "objectID": "EDA/eda.html",
    "href": "EDA/eda.html",
    "title": "EDA",
    "section": "",
    "text": "packages used\n\n\nCode\nlibrary(feasts) \nlibrary(tsibble)\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(zoo)       \nlibrary(forecast)   \nlibrary(tseries)   \nlibrary(patchwork) \nlibrary(here)\nlibrary(plotly)\nlibrary(xts)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggfortify)\n\n\n\n\nTime series plot\n\nBank of Korea base rateFederal Reserve effective rateKRW vs USD exchange rateUSD indexseoul real property price indexyield spread for USA & South korea: 10 years -3 yearsus-korea import and exportsS&P500 indexKOSPI index\n\n\n\n\nCode\nbok&lt;- read.csv(\"../data/interest/bok.csv\")%&gt;%\n  rename(Date = date)\nbok$Date&lt;- as.Date(bok$Date)\nbok &lt;- bok %&gt;%\n  mutate(Date = floor_date(Date, unit = \"quarter\")) %&gt;%\n  group_by(Date) %&gt;%\n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = \"drop\")\n\n\nggplot(bok, aes(x = Date, y = base_rate)) +\n  geom_line(color = \"skyblue\") +\n  labs(title = \"Bank of Korea base rate(quarterly) \",\n       x = \"Date\", y = \"Rate (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis time series plot shows a gentle downward trend from the early 2000s to 2020, then a sharp upswing during the 2021–23 tightening cycle and a recent leveling. There is no seasonality, policy rates don’t just move by considering only the calendar. Variation is moderate and step-like, reflecting discrete policy decisions rather than continuous noise. There are clear cyclical/periodic fluctuations aligned with business cycles: rapid cuts in 2008–09 and 2020, tightening in mid-2000s and post-COVID.\n\n\n\n\nCode\nusr&lt;- read.csv(\"../data/interest/us_rate.csv\")%&gt;%\n  rename(Date = observation_date,rate = DFF)\nusr$Date&lt;- as.Date(usr$Date)\n\nusr&lt;- usr %&gt;%\n  mutate(Date = floor_date(Date, unit = \"quarter\")) %&gt;%\n  group_by(Date) %&gt;%\n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = \"drop\")\n\nggplot(usr, aes(x = Date, y = rate)) +\n  geom_line(color = \"orange\") +\n  labs(title = \"Federal reserve effective rate(quarterly) \",\n       x = \"Date\", y = \"Rate (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nPlot shows tightening and easing cycles: high in the early 2000s, pinned near zero in 2009–15 and 2020–21, then rapid hikes from 2022. There is no seasonality,since policy rates affected by various economical reasons, seasonal factors are less important when considering policy rates. The long stretches at the zero lower bound and the subsequent aggressive normalization highlight the interaction of inflation shocks and recession risk.\n\n\n\n\nCode\nkr &lt;- read.csv(\"../data/fx rate/kor.csv\")\nkr &lt;- kr %&gt;%\n  transmute(\n    Date = as.Date(observation_date),\n    krw  = DEXKOUS,    \n    usd  = 1 / DEXKOUS  \n  ) %&gt;%\n  filter(!is.na(Date)) %&gt;%\n  arrange(Date) %&gt;%\n  distinct(Date, .keep_all = TRUE) %&gt;%\n  complete(Date = seq(min(Date), max(Date), by = \"day\")) %&gt;%\n\n  fill(krw, usd, .direction = \"down\")\n\n\nggplot(kr, aes(x = Date, y = usd)) +\n  geom_line(color = \"gold\") +\n  labs(title = \"KRW/USD exchange rate \",\n       x = \"Date\", y = \"USD\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe plot displays a long-run trend toward KRW depreciation punctuated by crisis spikes (late-1990s Asian crisis, 2008 GFC, 2020 COVID). Seasonality is not evident. Variation increases when the level is high, and medium-term cycles track global risk and U.S. monetary conditions. However overall it is hard to say for all time frame, there is a high variation(there are exceptional variation in one period).\n\n\n\n\nCode\nusd &lt;- read_csv(\"../data/fx rate/usd_index.csv\", show_col_types = FALSE)\n\nusd &lt;- usd %&gt;%\n  transmute(\n    Date = as.Date(Date),\n    usd_index = Close\n  ) %&gt;%\n  filter(!is.na(Date)) %&gt;%\n  arrange(Date) %&gt;%\n  distinct(Date, .keep_all = TRUE) %&gt;%\n  complete(Date = seq(min(Date), max(Date), by = \"day\")) %&gt;%\n  fill(usd_index, .direction = \"down\")\n\n\nggplot(usd, aes(x = Date, y = usd_index)) +\n  geom_line(color = \"darkblue\") +\n  labs(title = \"USD index \",\n       x = \"Date\", y = \"USD index\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nUSD index time series plot shows slow trend regimes—weakening after the mid-1980s peak, renewed strength around 2015–22—without seasonality; its variation is larger when the index is high; and long cycles reflect relative growth/real-rate differentials and safe-haven demand.\n\n\n\n\nCode\nhousing &lt;- read_csv(here(\"data/housing/seoul_housing.csv\"), skip = 3) %&gt;%\n  select(Date = `TIME_PERIOD:Period`, housing = `OBS_VALUE:Value`)%&gt;%\n  mutate(Date = as.Date(Date))\n\nhousing &lt;- housing %&gt;% mutate(Date = as.Date(Date))\n\n\nggplot(housing, aes(x = Date, y = housing)) +\n  geom_line(color = \"salmon2\") +\n  labs(title = \"Seoul Real Property Price Index \",\n       x = \"Date\", y = \"index \") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nSeoul real property price index plot shows A clear upward trend dominates, interrupted by corrections around 2008–12 and a sharp 2020–22 surge followed by partial pullback. seasonality is minimal, variation has grown with price levels.\n\n\n\n\nCode\nus_yield  &lt;- read.csv(here(\"data/yield\", \"us_yield.csv\"))\nkor_yield   &lt;- read.csv(here(\"data/yield\", \"kor_yield.csv\"))\n\n\nus_yield$Date  &lt;- as.Date(us_yield$Date)\nkor_yield$Date &lt;- as.Date(kor_yield$Date)\n\ncolnames(us_yield)[colnames(us_yield)  == \"X3Y\"]  &lt;- \"US_3Y\"\ncolnames(us_yield)[colnames(us_yield)  == \"X10Y\"] &lt;- \"US_10Y\"\ncolnames(kor_yield)[colnames(kor_yield) == \"X3Y\"]  &lt;- \"KR_3Y\"\ncolnames(kor_yield)[colnames(kor_yield) == \"X10Y\"] &lt;- \"KR_10Y\"\n\nus_yield  &lt;- us_yield[,  c(\"Date\", \"US_3Y\", \"US_10Y\")]\nkor_yield &lt;- kor_yield[, c(\"Date\", \"KR_3Y\", \"KR_10Y\")]\n\nus_yield  &lt;- us_yield  %&gt;% arrange(Date) %&gt;% fill(US_3Y, US_10Y, .direction = \"down\")\nkor_yield &lt;- kor_yield %&gt;% arrange(Date) %&gt;% fill(KR_3Y, KR_10Y, .direction = \"down\")\n\n\ndf &lt;- merge(us_yield, kor_yield, by = \"Date\")\n\ndf$US_3m10  &lt;- df$US_3Y - df$US_10Y\ndf$KR_3m10  &lt;- df$KR_3Y - df$KR_10Y\ndf$US_KR_3Y &lt;- df$US_3Y - df$KR_3Y\ndf$US_KR_10Y&lt;- df$US_10Y - df$KR_10Y\n\nfig &lt;- plot_ly(df, x = ~Date) |&gt;\n  add_lines(y = ~US_KR_3Y, name = \"US−KR (3Y)\") |&gt;\n  add_lines(y = ~US_KR_10Y, name = \"US−KR (10Y)\") |&gt;\n  layout(title = \"Yield Spreads: Term (3Y−10Y) and Cross-country (US−KR)\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Spread (pp)\"))\nfig\n\n\n\n\n\n\nyield spreads plot oscillate around zero with repeated cycles—notably inversions near recessions—show no seasonality, and maintain relatively stable variation in percentage points rather than scaling with level; taken together, they act as timely signals of policy divergence and cycle turns.\n\n\n\n\nCode\nimports &lt;- read_csv(here::here(\"data/trade\", \"imports.csv\"))\nexports &lt;- read_csv(here::here(\"data/trade\", \"exports.csv\"))\n\nclean_date &lt;- function(x) {\n  as.Date(paste0(sub(\"^([0-9]{4})([0-9]{2})$\", \"\\\\1-\\\\2\", gsub(\"/\", \"-\", as.character(x))), \"-01\"))\n}\n\nimports &lt;- imports %&gt;%\n  mutate(Date = clean_date(Date),\n         Type = \"Imports\")\n\nexports &lt;- exports %&gt;%\n  mutate(Date = clean_date(Date),\n         Type = \"Exports\")\ntrade &lt;- bind_rows(imports, exports)\n\nnames(trade)[2] &lt;- \"Value\"\n\ntrade_ts &lt;- trade %&gt;%\n  as_tsibble(index = Date, key = Type)\n\nautoplot(trade_ts, Value) +\n  labs(title = \"Monthly Imports and Exports: South korea vs USA\",\n       x = \"Date\", y = \"Trade Value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nBoth import and export time series plots shows strong secular trend as trade deepens. For seasonality, it is likely to exists, in terms of year frame there is up-down; this means in terms of monthly there is possibility for seasonality. This which might due to production of goods, shipping calendars. variation widens as volumes grow; and cyclical dips coincide with global shocks (2008–09, 2020).\n\n\n\n\nCode\nsp500 &lt;- read_csv(\"../data/stock/sp500.csv\")\n\nggplot(sp500, aes(x = Date, y = Close)) +\n  geom_line(color = \"red\") +\n  labs(title = \"S&P 500 index \",\n       x = \"Date\", y = \"S&P 500 index \") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThis plot features a steep long-run trend higher with pronounced cyclical bear markets (2000–02, 2008–09, 2020); there is no seasonality; variation increases alongside the level, producing larger rallies and drawdowns over time.\n\n\n\n\nCode\nkospi &lt;- read_csv(\"../data/stock/kospi.csv\")\nkospi$Date &lt;- as.Date(kospi$Date)\nggplot(kospi, aes(x = Date, y = Close)) +\n  geom_line(color = \"darkslategray2\") +\n  labs(title = \"KOSPI index\",\n       x = \"Date\", y = \"kospi index\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nKOSPI time series plot shows upward trend with long plateaus and sharp cyclical swings around crises is evident. seasonality is hard to observe and variation grows with the index level, compare with S&P500, it has larger variation.\n\n\n\nFrom the time-series plots, the S&P 500, KOSPI, and USD index appear multiplicative: while seasonality is hard to detect, their variation increases with the level (larger absolute swings when the series is high), and the dominant movements are multi-year cyclical regimes tied to macro conditions rather than calendar patterns. So for these variables will be log transformed.\n\n\nLag plots\n\nSouth korea base rateFederal Reserve rateKRW/USD FX ratetrade import South korea vs USAtrade export South korea vs USAUSA & South korea yield spread rate(3y)USA & South korea yield spread rate(10y)seoul housing property indexUSD indexKOSPI indexS&P 500 index\n\n\n\n\nCode\nbok_ts &lt;- ts(bok$base_rate, start = c(year(min(bok$Date)), month(min(bok$Date))), end = c(year(max(bok$Date)), month(max(bok$Date))),frequency = 4)\ngglagplot(bok_ts, do.lines=FALSE) +\n  xlab(\"Lags\") + ylab(\"Rate (%)\") +\n  ggtitle(\"Lag Plots — Bank of Korea Base Rate\") +\n  theme(axis.text.x=element_text(angle=45, hjust=1)) + theme_bw()\n\n\n\n\n\n\n\n\n\nThere is clear diagonal and tight clustering at lags 1–3 (strong positive autocorrelation). From about lag 4 onward the points spread and the diagonal weakens, having weak autocorrelation.\n\n\n\n\nCode\nusr_ts &lt;- ts(usr$rate, start = c(year(min(usr$Date)), month(min(usr$Date))), end = c(year(max(usr$Date)), month(max(usr$Date))),frequency=4)\n\ngglagplot(usr_ts, do.lines=FALSE) +\n  xlab(\"Lags\") + ylab(\"Rate (%)\") +\n  ggtitle(\"Lag Plots — U.S. Federal Funds Rate\") \n\n\n\n\n\n\n\n\n\nThere is strong diagonal at short lags, with values clustering at a few levels. After ~lag 4–5 the diagonal fades and scatter increases weaker, which in further lag, it seems that it has no autocorrelation.\n\n\n\n\nCode\nkr_ts&lt;- ts(kr$usd, frequency = 252, start = c(year(min(kr$Date)), month(min(kr$Date))), end = c(year(max(kr$Date)), month(max(kr$Date))))\ngglagplot(kr_ts, do.lines=FALSE) +\n  ggtitle(\"Lag Plots — KRW/USD FX rate\")+\n          xlab(\"Lags\")+ylab(\"KRW/USD FX rate\")\n\n\n\n\n\n\n\n\n\nThere is tight diagonal in every panel across all lags which means very high persistent autocorrelation for all lags.\n\n\n\n\nCode\nimport_ts&lt;- ts(imports$USD, frequency = 12, start = c(year(min(imports$Date)), month(min(imports$Date))), end = c(year(max(imports$Date)), month(max(imports$Date))))\ngglagplot(import_ts, do.lines=FALSE) +\n    ggtitle(\"Lag Plots — trade import South korea vs USA\")+\n          xlab(\"Lags\")+ylab(\"Trade import value\")\n\n\n\n\n\n\n\n\n\nThere is Pronounced diagonal through short–mid lags . At longer lags the diagonal remains but is wider which means positive but weakening autocorrelation.\n\n\n\n\nCode\nexport_ts&lt;- ts(exports$USD, frequency = 12, start = c(year(min(exports$Date)), month(min(exports$Date))), end = c(year(max(exports$Date)), month(max(exports$Date))))\ngglagplot(export_ts, do.lines=FALSE) +\n ggtitle(\"Lag Plots — trade export South korea vs USA\")+\n          xlab(\"Lags\")+ylab(\"Trade export value\")\n\n\n\n\n\n\n\n\n\nThere is Pronounced diagonal through short–mid lags . At longer lags the diagonal remains but is wider which means positive but weakening autocorrelation. It seems export has stronger autocorrelation than import for all plots.\n\n\n\n\nCode\nyield_3y_ts&lt;- ts(df$US_KR_3Y, frequency = 252, start = c(year(min(df$Date)), month(min(df$Date))), end = c(year(max(df$Date)), month(max(df$Date))))\ngglagplot(yield_3y_ts, do.lines=FALSE) +\n  ggtitle(\"Lag Plots — USA & South korea yield spread rate(3y)\")+\n          xlab(\"Lags\")+ylab(\"yield % \")\n\n\n\n\n\n\n\n\n\nThere is high autocorrelation across lags, with slightly more dispersion than the 10-year series.\n\n\n\n\nCode\nyield_10y_ts&lt;- ts(df$US_KR_10Y, frequency = 252, start = c(year(min(df$Date)), month(min(df$Date))), end = c(year(max(df$Date)), month(max(df$Date))))\ngglagplot(yield_10y_ts, do.lines=FALSE) +\n  ggtitle(\"Lag Plots — USA & South korea yield spread rate(10y)\")+\n          xlab(\"Lags\")+ylab(\"yield % \")\n\n\n\n\n\n\n\n\n\nDiagonal stays crisp across nearly all lags which has strong and long-horizon autocorrelation.\n\n\n\n\nCode\n#house_ts&lt;- ts(housing$housing, frequency = 12, start = c(year(min(housing$Date))))\nhouse_ts&lt;- ts(housing$housing, frequency = 12, start = c(year(min(housing$Date)), month(min(housing$Date))), end = c(year(max(housing$Date)), month(max(housing$Date))))\ngglagplot(house_ts, do.lines=FALSE) +\n    ggtitle(\"Lag Plots — seoul housing property index\")+\n          xlab(\"Lags\")+ylab(\"Seoul House index\") +\n          theme(axis.text.x=element_text(angle=45, hjust=1))\n\n\n\n\n\n\n\n\n\nThere is strong near-linear relationship at every lag; slight curvature at higher lags.\n\n\n\n\nCode\nusd_ts_log &lt;- ts(log(usd$usd_index), start = c(year(min(usd$Date)), month(min(usd$Date))), end = c(year(max(usd$Date)), month(max(usd$Date))), frequency = 252)\n#usd_ts_log &lt;- ts(log(usd$usd_index), start=min(usd$Date), frequency=252)\n\ngglagplot(usd_ts_log, do.lines=FALSE) +\n  ggtitle(\"Lag Plots — USD index (log)\")+\n          xlab(\"Lags\")+ylab(\"USD index\") +\n          theme(axis.text.x=element_text(angle=45, hjust=1))\n\n\n\n\n\n\n\n\n\nThere is tight diagonal in every panel across all lags which means very high persistent autocorrelation for all lags.\n\n\n\n\nCode\nkospi_ts_log &lt;- ts(log(kospi$Close), start = c(year(min(kospi$Date)), month(min(kospi$Date))), end = c(year(max(kospi$Date)), month(max(kospi$Date))), frequency = 252)\n\ngglagplot(kospi_ts_log, do.lines=FALSE) +\n  xlab(\"Lags\") + ylab(\"log(Price)\") +\n  ggtitle(\"Lag Plots — KOSPI (log)\") \n\n\n\n\n\n\n\n\n\nWhile there are some point that are off the line, but in general it is tight diagonal in every panel across all lags which means very high persistent autocorrelation for all lags.\n\n\n\n\nCode\nsp_ts_log &lt;- ts(log(sp500$Close), start = c(year(min(sp500$Date)), month(min(sp500$Date))), end = c(year(max(sp500$Date)), month(max(sp500$Date))), frequency = 252)\n                                              \ngglagplot(sp_ts_log, do.lines=FALSE) +\n  xlab(\"Lags\") + ylab(\"log(Price)\") +\n  ggtitle(\"Lag Plots — S&P 500 (log)\") +\n  theme(axis.text.x=element_text(angle=45, hjust=1)) + theme_bw()\n\n\n\n\n\n\n\n\n\nThere is tight diagonal in every panel across all lags which means very high persistent autocorrelation for all lags.\n\n\n\n\n\nDecomposition\n\nSouth korea base rateFederal Reserve rateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South korea yield spread rate(3y)USA & South korea yield spread rate(10y)seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\nbok_stl &lt;- stl(bok_ts, s.window = \"periodic\", robust = TRUE)\nautoplot(bok_stl) +\n  labs(title = \"STL Decomposition — BOK Base Rate (Additive)\",\n       x = \"Date\", y = \"Rate (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe decomposition is dominated by a smooth trend that drifts down from the mid-2000s into 2019–21, then inflects upward as policy tightens post-pandemic. The seasonal component is very small and roughly constant through time—its amplitude doesn’t expand when the level is higher—so it reads like a nuisance wiggle rather than a percentage effect. The remainder captures a few localized shocks (notably around 2009 and 2023) with variance that doesn’t scale with the policy level. Those cues point to an additive specification in levels.\n\n\n\n\nCode\nusr_stl &lt;- stl(usr_ts, s.window = \"periodic\", robust = TRUE)\nautoplot(usr_stl) +\n  labs(title = \"STL Decomposition — US Fed Funds (Additive)\",\n       x = \"Date\", y = \"Rate (%)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nThe trend captures long tightening/easing cycles: near-zero from 2009–2015, hiking into 2019, a pandemic reset in 2020, and the rapid 2022–2023 liftoff. Seasonality is negligible and does not grow with the level—typical of policy rates that move in discrete steps rather than proportional swings. The remainder is episodic (crisis windows) but its magnitude is broadly stable in absolute terms. That pattern supports an additive decomposition.\n\n\n\n\nCode\ndecompose_kr_ts&lt;- decompose(kr_ts)\nautoplot(decompose_kr_ts,main = \"decomposition: KRW/USD FX rate\")\n\n\n\n\n\n\n\n\n\nThe trend reflects multi-year won weakness/strength cycles, with standout moves in 2008–09 and again around 2022. Seasonality is mild and appears roughly constant in absolute size; it doesn’t fan out as the level drifts, so an additive form is better option.\n\n\n\n\nCode\ndecompose_import_ts&lt;- decompose(import_ts)\nautoplot(decompose_import_ts,main = \"decomposition: trade import South Korea vs USA\")\n\n\n\n\n\n\n\n\n\nCode\ndecompose_import_ts1&lt;- decompose(export_ts,\"multiplicative\")\nautoplot(decompose_import_ts1,main = \"decomposition: trade import South Korea vs USA(multiplicative)\")\n\n\n\n\n\n\n\n\n\nThe trend shows a secular rise with cyclical dents (late 1990s, GFC, 2020) consistent with globalization and demand cycles. In levels, the seasonal pattern clearly widens over time and the remainder becomes more volatile as the series grows—classic heteroskedasticity that violates additive assumptions. On a multiplicative scale, seasonality becomes approximately constant in percentage terms, and the remainder tightens around zero. This yields a cleaner, more interpretable decomposition for strictly positive, growing trade flows.\n\n\n\n\nCode\ndecompose_export_ts&lt;- decompose(export_ts)\nautoplot(decompose_export_ts,main = \"decomposition: trade export South Korea vs USA(additive)\")\n\n\n\n\n\n\n\n\n\nCode\ndecompose_export_ts1&lt;- decompose(export_ts,\"multiplicative\")\nautoplot(decompose_export_ts1,main = \"decomposition: trade export South Korea vs USA(multiplicative)\")\n\n\n\n\n\n\n\n\n\nExports exhibit a strong upward trend with cyclical pauses and a noticeable surge post-2016 before cooling. The additive view shows seasonality and residual variance that expand alongside the level, indicating proportional—not absolute—effects. Switching to multiplicative stabilizes both, turning the seasonal shape into a near-constant proportion of the level and shrinking the remainder to a level-invariant band. That makes inference about turning points in the trend more reliable.\n\n\n\n\nCode\ndecompose_3y_ts&lt;- decompose(yield_3y_ts)\nautoplot(decompose_3y_ts,main = \"decomposition: USA & South korea yield spread rate(3y)\")\n\n\n\n\n\n\n\n\n\nThe trend meanders from negative values in the early 2000s toward positive territory around the late 2010s before sliding again, mirroring cross-country policy cycles and term-structure dynamics. Because the series crosses zero and can be negative, multiplicative models are not meaningful here. The seasonal component is modest and stable; the remainder features short bursts of volatility (pandemic, 2023) that don’t scale with the spread’s absolute level. An additive decomposition is therefore appropriate.\n\n\n\n\nCode\ndecompose_10y_ts&lt;- decompose(yield_10y_ts)\nautoplot(decompose_10y_ts,main =  \"decomposition: USA & South korea yield spread rate(10y)\")\n\n\n\n\n\n\n\n\n\nThere is upward trend through the mid-2010s gives way to a more pronounced decline after 2021, highlighting shifts in long-run rate differentials. As with the 3-year, the spread can be near or below zero, which rules out multiplicative forms. Seasonality is small, and the remainder shows occasional spikes that are fairly constant in absolute magnitude. The overall structure fits best with an additive model.\n\n\n\n\nCode\ndecompose_housing_ts&lt;- decompose(house_ts)\nautoplot(decompose_housing_ts,main = \"decomposition: Seoul housing property index\" )\n\n\n\n\n\n\n\n\n\nThe trend rises steadily, quickening around 2019–2021 before easing, while the seasonal component stays roughly the same amplitude across the sample, not widening as the index level increases. That constancy in absolute seasonal size argues for an additive form rather than multiplicative. The remainder shows episodic bumps—policy moves and sentiment shifts—but its variance doesn’t systematically scale with the level, so an additive decomposition cleanly separates the smooth trend\n\n\n\n\nCode\ndecompose_usd_ts&lt;- decompose(usd_ts_log)\nautoplot(decompose_usd_ts, main= \"decomposition: USD index\")\n\n\n\n\n\n\n\n\n\nThe trend captures well-known dollar cycles (strong mid-1980s, mid-2010s; softer interludes) while the seasonal component is persistent but proportionate to the level. In raw levels, the remainder tends to be larger when the index is higher; logging or using a multiplicative form evens that out. Decomposing multiplicatively yields cleaner inference: seasonality as a percent swing and a remainder that is closer to level-invariant.\n\n\n\n\nCode\ndecompose_kospi_ts&lt;- decompose(kospi_ts_log)\nautoplot(decompose_kospi_ts,main = \"decomposition: KOSPI index\")\n\n\n\n\n\n\n\n\n\nThe trend reflects a secular climb punctuated by sharp drawdowns (GFC, COVID, 2022–23). Equity markets exhibit volatility clustering and proportional variation: the seasonal and remainder amplitudes grow as the level rises. On logs (or multiplicatively), the seasonal share becomes roughly constant and the residual shocks are better behaved. This improves signal extraction around turning points and reduces spurious variance in the remainder.\n\n\n\n\nCode\ndecompose_sp_ts&lt;- decompose(sp_ts_log)\nautoplot(decompose_sp_ts,main = \"decomposition: S&P500 index\" )\n\n\n\n\n\n\n\n\n\nA strong upward trend dominates, with pauses and breaks around 2000–02, 2008–09, and 2020 before resuming higher. Seasonality is small but inherently proportional in equity prices, and the remainder is much noisier in bull markets when viewed in levels. A multiplicative/log-additive decomposition stabilizes variance, rendering seasonality as a constant percentage and isolating shocks without level-driven inflation of the residual. This specification typically produces the most interpretable components for stock indices.\n\n\n\n\n\nACF & PACF plot\n\nSouth korea base rateFederal Reserve RateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South Korea yield spread rate(3Y)USA & South Korea yield spread rate(10Y)Seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\nggAcf(bok_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of South Korea base rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(bok_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of South Korea base rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a very slow, gradual decay with high correlations extending well beyond lag 20, remaining above 0.25 throughout. The PACF shows a single strong spike at lag 1 of approximately 0.95, then cuts off sharply afterward with all subsequent lags staying within the confidence bounds. This is a classic signature of a highly persistent autoregressive process. This series is clearly non-stationary. The slow decay in the ACF is a classic signature of a unit root or near-unit root process. The PACF pattern suggests an AR(1) process with a coefficient very close to 1, indicating a random walk or highly persistent process. This makes economic sense as central banks adjust interest rates gradually rather than making abrupt changes. First differencing would be needed to achieve stationarity\n\n\n\n\nCode\nggAcf(usr_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of Federal Reserve Rate \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(usr_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of Federal Reserve Rate \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows slow decay similar to the South Korea rate, though slightly faster, with correlations gradually declining but remaining substantial even at longer lags. The PACF shows a dominant spike at lag 1 of approximately 0.95, with subsequent lags mostly within bounds, though there are some minor scattered exceedances at longer lags. This series is also non-stationary with similar characteristics to the South Korea rate. The persistent autocorrelation indicates the series has memory and trends, which aligns with how the Federal Reserve conducts monetary policy through gradual adjustments. The slow decay pattern confirms that the series doesn’t revert to a mean quickly. Differencing is required for stationarity before any modeling can proceed.\n\n\n\n\nCode\nggAcf(kr_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of KRW/USD FX rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(kr_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of  KRW/USD FX rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows extremely strong persistence with correlations near 1.0 extending across all 50+ lags with barely any decay visible. The PACF shows a massive spike at lag 1 of approximately 1.0, followed by an immediate and complete cutoff with all other lags remaining within the confidence bounds. This is perhaps the clearest example of a pure random walk in the dataset. This series is strongly non-stationary and represents an almost perfect random walk. The ACF barely decays at all, which is characteristic behavior for exchange rates in floating rate regimes. Exchange rates typically follow random walk processes as they respond to news and changing economic conditions without mean reversion. This series definitely requires first differencing, or preferably a returns transformation, to achieve stationarity.\n\n\n\n\nCode\nggAcf(import_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of trade import South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(import_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of trade import South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows very high initial values with slow decay, remaining above 0.7 even at lag 24, indicating strong persistence in the series. The PACF shows a very strong spike at lag 1 of approximately 0.95, then a smaller but still significant spike at lag 2, followed by scattered minor spikes at various longer lags within or just outside the confidence bounds. This series is non-stationary with strong persistence. The PACF suggests this might be an AR(2) process in differences, or possibly requires seasonal differencing given the trade data nature. Trade flows typically have both trend components and potential seasonal patterns. First differencing is recommended, and you may want to check for seasonal patterns that would require additional seasonal differencing or adjustment.\n\n\n\n\nCode\nggAcf(export_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of trade export South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(export_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of trade export South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF pattern is very similar to the import series, showing slow decay with high persistence and correlations remaining elevated throughout the lag structure. The PACF shows a dominant lag 1 spike of approximately 0.95, a smaller but noticeable lag 2 spike, and then mostly lags within bounds with occasional minor exceedances at longer lags. This series is non-stationary with characteristics nearly identical to the import series. This similarity makes economic sense as exports and imports often move together and share common trends related to economic cycles and bilateral trade relationships. First differencing is needed, and like the import series, you should consider checking for seasonal patterns that might require additional treatment beyond simple first differencing.\n\n\n\n\nCode\nggAcf(yield_3y_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of USA & South Korea yield spread rate(3Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(yield_3y_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of USA & South Korea yield spread rate(3Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows extremely high persistence with correlations remaining near 1.0 across all 50 lags, displaying almost no decay whatsoever. The PACF shows a dominant spike at lag 1 of approximately 0.99, followed by a small spike at lag 2, after which all subsequent lags remain within the confidence bounds. This represents one of the most persistent series in the dataset. This series is clearly non-stationary and exhibits random walk behavior. The yield spread between the two countries appears to drift over time without any mean reversion, possibly reflecting changing perceptions of relative risk, monetary policy divergence, or capital flow patterns. First differencing is absolutely required before any modeling can be performed on this series.\n\n\n\n\nCode\nggAcf(yield_10y_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of USA & South Korea yield spread rate(10Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(yield_10y_ts,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of USA & South Korea yield spread rate(10Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF pattern is nearly identical to the 3Y spread, showing very high persistence across all lags with correlations staying close to 1.0 throughout the entire lag structure. The PACF displays the same structure with a strong lag 1 spike of approximately 0.99, a smaller but noticeable lag 2 spike, and then a sharp cutoff with all remaining lags within bounds. This series is strongly non-stationary. Both the 3Y and 10Y spreads show identical non-stationary behavior, which suggests persistent divergences or convergences in the yield curves between the two countries driven by common factors. The similarity between the two maturities suggests they might be cointegrated. This series requires first differencing before it can be used in any time series models.\n\n\n\n\nCode\nggAcf(house_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of Seoul housing  property index \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(house_ts) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of Seoul housing  property index \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a slow, linear decay pattern starting from about 0.98 and gradually declining to approximately 0.55 by lag 24, representing moderately fast decay compared to financial indices. The PACF displays a massive spike at lag 1 of about 0.98, after which all subsequent lags remain comfortably within the confidence bounds with no other significant spikes visible. This series is non-stationary as expected for real estate price indices, which typically trend upward over time due to population growth, income increases, and inflation. The decay in the ACF is somewhat faster than pure financial indices, possibly reflecting some degree of mean reversion in housing markets. First differencing is needed before modeling this series, and seasonal adjustment might also be worth considering.\n\n\n\n\nCode\nggAcf(usd_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of USD index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(usd_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of USD index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows near-perfect persistence with correlations at 1.0 extending uniformly across all 50+ lags without any visible decay throughout the entire range. The PACF displays an almost perfect spike at lag 1 approaching 1.0, followed by an immediate and complete cutoff to values near zero for all remaining lags. This is perhaps the most extreme example of random walk behavior in the entire dataset. This series is extremely non-stationary, exhibiting textbook random walk characteristics. Dollar indices tend to follow this pattern as they drift based on relative monetary policy stances, economic conditions across countries, and international capital flows. The complete lack of mean reversion indicates the dollar’s value can move in any direction for extended periods. First differencing or computing log returns is definitely required before any analysis or modeling can proceed.\n\n\n\n\nCode\nggAcf(kospi_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of KOSPI index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(kospi_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of KOSPI index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows extremely high persistence with correlations remaining near 1.0 across all 50 lags without meaningful decay, indicating very strong memory in the series. The PACF displays a dominant lag 1 spike of approximately 0.99 followed by an immediate cutoff, with all subsequent lags staying within the confidence bounds. This is the standard pattern observed for equity price indices worldwide. This series is strongly non-stationary, which is typical behavior for stock market indices. Like most equity indices worldwide, KOSPI follows a random walk with long-term upward trends reflecting economic growth and corporate earnings expansion, but no reversion to a fixed mean level. First differencing is required, though using log returns would be even better for financial analysis purposes as they have better statistical properties.\n\n\n\n\nCode\nggAcf(sp_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"ACF of S&P500 index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(sp_ts_log,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"PACF of S&P500 index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF pattern is virtually identical to the KOSPI, showing near-perfect persistence with correlations at 1.0 across all lags without any visible decay. The PACF shows the characteristic lag 1 spike of approximately 1.0 with a sharp, immediate cutoff afterward. All remaining lags stay comfortably within the confidence bounds, confirming the unit root structure typical of equity indices. This series is strongly non-stationary and exhibits classic random walk behavior identical to the KOSPI. This similarity confirms that equity indices worldwide share common stochastic properties regardless of the specific market or country, reflecting the general nature of stock prices. First differencing or log returns are required before any modeling, with log returns being strongly preferred for financial applications due to their better distributional properties and interpretation as continuously compounded returns.\n\n\n\n\n\nAugmented Dickey-Fuller Test\n\nSouth korea base rateFederal Reserve rateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South korea yield spread rate(3y)USA & South korea yield spread rate(10y)seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\nadf.test(bok_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  bok_ts\nDickey-Fuller = -1.6484, Lag order = 4, p-value = 0.7225\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(usr_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  usr_ts\nDickey-Fuller = -2.6475, Lag order = 4, p-value = 0.308\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(kr_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  kr_ts\nDickey-Fuller = -2.0722, Lag order = 22, p-value = 0.5478\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(import_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  import_ts\nDickey-Fuller = -2.9309, Lag order = 7, p-value = 0.1841\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(export_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  export_ts\nDickey-Fuller = -2.0023, Lag order = 7, p-value = 0.5762\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(yield_3y_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  yield_3y_ts\nDickey-Fuller = -1.7543, Lag order = 18, p-value = 0.6824\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(yield_10y_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  yield_10y_ts\nDickey-Fuller = -2.7481, Lag order = 18, p-value = 0.2615\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(house_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  house_ts\nDickey-Fuller = -2.556, Lag order = 6, p-value = 0.3418\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(usd_ts_log)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  usd_ts_log\nDickey-Fuller = -2.1606, Lag order = 22, p-value = 0.5103\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(kospi_ts_log)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  kospi_ts_log\nDickey-Fuller = -1.24, Lag order = 19, p-value = 0.9001\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(sp_ts_log)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  sp_ts_log\nDickey-Fuller = -1.758, Lag order = 20, p-value = 0.6809\nalternative hypothesis: stationary\n\n\n\n\n\nFor all plots, the p-value is greater than 0.05, which fails to reject null hypothesis. This means, all the plots are non-stationary. So, conducting further approach is required to ensure that each plots can become stationary. This aligns with what all of our ACF/PACF plots shows.\n\n\nDifferencing\n\nSouth korea base rateFederal Reserve RateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South Korea yield spread rate(3Y)USA & South Korea yield spread rate(10Y)Seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\nbok_diff&lt;- diff(bok_ts)\nggAcf(bok_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of South Korea base rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(bok_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of South Korea base rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a significant spike at lag 1 of approximately 0.37, followed by smaller spikes at lags 2-3, with some negative correlations appearing around lags 8-11. Most lags beyond lag 3 remain within the confidence bounds. The PACF shows a dominant spike at lag 1, followed by scattered smaller spikes at various lags including around lag 13. Overall, most correlations have diminished substantially compared to the original series. After first differencing, this series appears to be closer to stationarity.\n\n\n\n\nCode\nusr_diff&lt;- diff(usr_ts)\n\nggAcf(usr_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of Federal Reserve Rate \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(usr_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of Federal Reserve Rate \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF displays significant positive spikes at lags 1, 2, and 3 (around 0.6, 0.5, and 0.35 respectively), followed by several negative spikes around lags 7-11. The pattern shows a slow oscillating decay. The PACF shows a very large spike at lag 1 and then most other lags remain within bounds, with some scattered minor exceedances. This pattern differs noticeably from the South Korea rate. This series shows evidence of remaining non-stationarity or strong autocorrelation even after first differencing.\n\n\n\n\nCode\nkr_diff&lt;- diff(kr_ts)\n\nggAcf(kr_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of KRW/USD FX rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(kr_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of  KRW/USD FX rate\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows many small spikes scattered throughout the lags, with most staying within or just barely outside the confidence bounds. The correlations appear fairly random with no clear pattern, hovering close to zero. The PACF displays a similar pattern with multiple small spikes at various lags (notably around lags 8, 20, 27, 38, and 42), but most remain small in magnitude and many are within the confidence bounds. This differenced series appears to be stationary and close to white noise. The lack of strong patterns in both ACF and PACF suggests that first differencing has successfully removed the non-stationary component.\n\n\n\n\nCode\nimport_diff &lt;- diff(import_ts)\n\nggAcf(import_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of trade import South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(import_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of trade import South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a very large negative spike at lag 1 (approximately -0.45), followed by mostly random small spikes that stay within confidence bounds. The PACF displays an extremely large negative spike at lag 1 (nearly -0.5), with most other lags remaining within bounds except for a few minor exceedances at lags around 6, 8, and 23. This series appears stationary after differencing but exhibits strong negative autocorrelation.\n\n\n\n\nCode\nexport_diff &lt;- diff(export_ts)\n\nggAcf(export_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of trade export South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(export_diff) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of trade export South Korea vs USA\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows significant positive spikes at lags 5 and 12, and a significant spike at lag 24, suggesting potential seasonal patterns. Most other lags remain within bounds with scattered minor exceedances. The PACF shows positive spikes at lags 5, 12, and 24, with most other lags within bounds, reinforcing the suggestion of seasonality in the data. This series appears stationary after first differencing, but exhibits clear seasonal patterns.\n\n\n\n\nCode\nyield_3y_ts_diff &lt;- diff(yield_3y_ts)\n\nggAcf(yield_3y_ts_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of USA & South Korea yield spread rate(3Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(yield_3y_ts_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of USA & South Korea yield spread rate(3Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a very large negative spike at lag 1 (approximately -0.12), with all other lags appearing as small random fluctuations within the confidence bounds. The PACF displays a similar pattern with a large negative spike at lag 1 and all other lags remaining comfortably within bounds. The correlations are much smaller in magnitude compared to the interest rate series. This series appears stationary after first differencing.\n\n\n\n\nCode\nyield_10y_ts_diff &lt;- diff(yield_10y_ts)\n\nggAcf(yield_10y_ts_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of USA & South Korea yield spread rate(10Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(yield_10y_ts_diff,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of USA & South Korea yield spread rate(10Y)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a large negative spike at lag 1 (approximately -0.11), with scattered small spikes throughout but most remaining within bounds. There are some notable spikes around lags 8, 40-42, and 49. The PACF shows a similar large negative spike at lag 1, with most other lags within bounds except for some minor exceedances at longer lags around 40-50. This series is stationary after first differencing, very similar to the 3Y spread.\n\n\n\n\nCode\nhouse_dlog &lt;- diff(house_ts)\n\nggAcf(house_dlog) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of Seoul housing  property index \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(house_dlog) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of Seoul housing  property index \") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows a very large positive spike at lag 1 (approximately 0.87), followed by strong positive spikes at lags 2 (0.70) and 3 (0.52), with a clear exponential decay pattern continuing through about lag 7. After lag 7, correlations become small but some remain just outside bounds. The PACF shows a massive spike at lag 1 (around 0.87) and then all subsequent lags remain within the confidence bounds. This series seems NOT stationary even after first differencing. The extremely high lag 1 autocorrelation and slow decay in the ACF strongly suggest that first differencing was insufficient. For this, second order differencing will be conducted later.\n\n\n\n\nCode\n#log\n\nusd_dlog &lt;- diff(usd_ts_log) \n\nggAcf(usd_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of USD index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(usd_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of USD index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows small correlations scattered throughout all lags, with most remaining within the confidence bounds. There are a few lags that barely exceed the bounds (notably around lags 1, 20, and 30), but the magnitudes are very small (all under 0.04). The PACF displays a similar pattern with many small spikes scattered across lags, with a couple just exceeding the bounds around lags 1, 20, and 30, but again all are small in magnitude. This differenced series appears to be stationary. The lack of any strong patterns in both ACF and PACF, combined with the very small magnitudes of all correlations, suggests that first differencing has successfully removed the non-stationary component.\n\n\n\n\nCode\n#log\n\nkospi_dlog &lt;- diff(kospi_ts_log) \n\nggAcf(kospi_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of KOSPI index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(kospi_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of KOSPI index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows small positive correlations at various lags, with no strong decay pattern. Most lags remain within bounds, though there are noticeable spikes at lags around 1, 12-13, and 48-49, all staying relatively small in magnitude (under 0.03). The PACF shows a similar scattered pattern with small spikes throughout, with slightly larger ones at lags 1, 12, and 48, but most correlations are close to zero and within the confidence bounds. This differenced series appears to be stationary. The correlations are all very small, suggesting that first differencing has effectively removed the trend component.\n\n\n\n\nCode\n#log \n\nsp_dlog &lt;- diff(sp_ts_log) \n\nggAcf(sp_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"blue\") +\n  labs(title = \"Differenced: ACF of S&P500 index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nCode\nggPacf(sp_dlog,lag.max = 50) +\n  geom_segment(aes(xend = lag, yend = 0), color=\"red\") +\n  labs(title = \"Differenced: PACF of S&P500 index\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n\nThe ACF shows small correlations scattered across all lags with no clear decay pattern. There are a few notable spikes that exceed the confidence bounds at lags around 7, 13, 15, 28, and 47, but all remain small in magnitude (under 0.03). Most lags are very close to zero. The PACF displays a similar pattern with scattered small spikes, including some that exceed bounds at lags 7, 13, 15, 28, and 32, but again all are small in magnitude. This differenced series appears to be stationary. Like the KOSPI, the S&P500 in differences shows very weak autocorrelation patterns, consistent with efficient market behavior.\n\n\n\n\n\nAugmented Dickey-Fuller Test after differencing\n\nSouth korea base rateFederal Reserve rateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South korea yield spread rate(3y)USA & South korea yield spread rate(10y)seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\nadf.test(bok_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  bok_diff\nDickey-Fuller = -4.7709, Lag order = 4, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(usr_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  usr_diff\nDickey-Fuller = -4.6918, Lag order = 4, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(kr_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  kr_diff\nDickey-Fuller = -17.413, Lag order = 22, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(import_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  import_diff\nDickey-Fuller = -9.3481, Lag order = 7, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(export_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  export_diff\nDickey-Fuller = -8.1974, Lag order = 7, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(yield_3y_ts_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  yield_3y_ts_diff\nDickey-Fuller = -19.172, Lag order = 18, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(yield_10y_ts_diff)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  yield_10y_ts_diff\nDickey-Fuller = -18.933, Lag order = 18, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(house_dlog)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  house_dlog\nDickey-Fuller = -4.2819, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(usd_dlog)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  usd_dlog\nDickey-Fuller = -20.949, Lag order = 22, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(kospi_dlog)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  kospi_dlog\nDickey-Fuller = -19.46, Lag order = 19, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\n\nCode\nadf.test(sp_dlog)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  sp_dlog\nDickey-Fuller = -21.152, Lag order = 20, p-value = 0.01\nalternative hypothesis: stationary\n\n\n\n\n\nFor all plots, the p-value is greater than 0.05, which fails to reject null hypothesis. This means, all the plots are non-stationary. So, conducting further approach is required to ensure that each plots can become stationary. This aligns with what all of our ACF/PACF plots shows except seoul housing index, which second order will be conducted(in univariate section) for accurate result.\n\n\nMoving Average\n\nSouth Korea base rateFederal Reserve rateKRW/USD FX ratetrade import South Korea vs USAtrade export South Korea vs USAUSA & South korea yield spread rate(3y)USA & South korea yield spread rate(10y)seoul housing property indexUSD indexKOSPI indexS&P500 index\n\n\n\n\nCode\ndates  &lt;- as.Date(as.yearqtr(time(bok_ts)))            \nbok_df &lt;- data.frame(Date = dates, Value = as.numeric(bok_ts)) \nbok_df$MA3 &lt;- rollmean(bok_df$Value, 3, fill = NA, align = \"right\")\nbok_df$MA6 &lt;- rollmean(bok_df$Value,6, fill = NA, align = \"right\")\nbok_df$MA12 &lt;- rollmean(bok_df$Value, 12, fill = NA, align = \"right\")\n\nplot_ly(bok_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"South Korea base rate\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA3, name = \"MA3\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA6, name = \"MA6\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA12, name = \"MA12\", line = list(color = \"green\")) %&gt;%\n  layout(title = \" South Korea base rate with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Rate (%)\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndates  &lt;- as.Date(as.yearqtr(time(usr_ts)))              \nusr_df &lt;- data.frame(Date = dates, Value = as.numeric(usr_ts))  \n\nusr_df$MA3 &lt;- rollmean(usr_df$Value, 3, fill = NA, align = \"right\")\nusr_df$MA6 &lt;- rollmean(usr_df$Value,6, fill = NA, align = \"right\")\nusr_df$MA12 &lt;- rollmean(usr_df$Value, 12, fill = NA, align = \"right\")\n\nplot_ly(usr_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"Federal Reserve rate\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA3, name = \"MA3\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA6, name = \"MA6\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA12, name = \"MA12\", line = list(color = \"green\")) %&gt;%\n  layout(title = \" Federal Reserve rate with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Rate (%)\"))\n\n\n\n\n\n\n\n\n\n\nCode\nkr_ts &lt;- ts(kr$usd,\n            start = c(year(min(kr$Date)), 1),\n            frequency = 252)\n\nkr_df &lt;- data.frame(Date = kr$Date, Value = as.numeric(kr_ts))\n\nkr_df$MA50 &lt;- rollmean(kr_df$Value, 50, fill = NA, align = \"right\")\nkr_df$MA100 &lt;- rollmean(kr_df$Value, 100, fill = NA, align = \"right\")\nkr_df$MA200 &lt;- rollmean(kr_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(kr_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"KRW/USD spot rate\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \" KRW/USD spot rate with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"KRW/USD\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndates &lt;- as.Date(as.yearmon(time(import_ts)))             \nimport_df &lt;- data.frame(Date = dates, Value = as.numeric(import_ts))  \nimport_df$MA12 &lt;- rollmean(import_df$Value, 12, fill = NA, align = \"right\")\nimport_df$MA24 &lt;- rollmean(import_df$Value, 24, fill = NA, align = \"right\")\nimport_df$MA36 &lt;- rollmean(import_df$Value, 36, fill = NA, align = \"right\")\n\nplot_ly(import_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"trade import South Korea vs USA\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA12, name = \"MA12\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA24, name = \"MA24\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA36, name = \"MA36\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"Trade import South Korea vs USA with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"trade import South Korea vs USA\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndates &lt;- as.Date(as.yearmon(time(export_ts)))              \nexport_df &lt;- data.frame(Date = dates, Value = as.numeric(export_ts)) \nexport_df$MA12 &lt;- rollmean(export_df$Value, 12, fill = NA, align = \"right\")\nexport_df$MA24 &lt;- rollmean(export_df$Value, 24, fill = NA, align = \"right\")\nexport_df$MA36 &lt;- rollmean(export_df$Value, 36, fill = NA, align = \"right\")\n\nplot_ly(export_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"trade export South Korea vs USA\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA12, name = \"MA12\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA24, name = \"MA24\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA36, name = \"MA36\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"Trade export South Korea vs USA with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"trade export South Korea vs USA\"))\n\n\n\n\n\n\n\n\n\n\nCode\nyield_3y_ts &lt;- ts(df$US_KR_3Y,\n            start = c(year(min(df$Date)), 1),\n            frequency = 252)\n\nyield_3y_df &lt;- data.frame(Date = df$Date, Value = as.numeric(yield_3y_ts))\n\nyield_3y_df$MA50 &lt;- rollmean(yield_3y_df$Value, 50, fill = NA, align = \"right\")\nyield_3y_df$MA100 &lt;- rollmean(yield_3y_df$Value, 100, fill = NA, align = \"right\")\nyield_3y_df$MA200 &lt;- rollmean(yield_3y_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(yield_3y_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"USA & South korea yield spread rate(3y)\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"USA & South korea yield spread rate(3y) with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Rate (%)\"))\n\n\n\n\n\n\n\n\n\n\nCode\nyield_10y_ts &lt;- ts(df$US_KR_10Y,\n            start = c(year(min(df$Date)), 1),\n            frequency = 252)\nyield_10y_df &lt;- data.frame(Date = df$Date, Value = as.numeric(yield_10y_ts))\n\n\nyield_10y_df$MA50 &lt;- rollmean(yield_3y_df$Value, 50, fill = NA, align = \"right\")\nyield_10y_df$MA100 &lt;- rollmean(yield_3y_df$Value, 100, fill = NA, align = \"right\")\nyield_10y_df$MA200 &lt;- rollmean(yield_3y_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(yield_10y_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"USA & South korea yield spread rate(10y)\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"USA & South korea yield spread rate(10y) with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Rate (%)\"))\n\n\n\n\n\n\n\n\n\n\nCode\ndates &lt;- as.Date(as.yearmon(time(house_ts)))              \nhousing_df &lt;- data.frame(Date = dates, Value = as.numeric(house_ts)) \n\n\nhousing_df$MA12 &lt;- rollmean(housing_df$Value, 12, fill = NA, align = \"right\")\nhousing_df$MA24 &lt;- rollmean(housing_df$Value, 24, fill = NA, align = \"right\")\nhousing_df$MA36 &lt;- rollmean(housing_df$Value, 36, fill = NA, align = \"right\")\n\nplot_ly(housing_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"Seoul housing property index\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA12, name = \"MA12\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA24, name = \"MA24\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA36, name = \"MA36\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"Seoul housing property Index with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"Housing Index\"))\n\n\n\n\n\n\n\n\n\n\nCode\nusd_ts &lt;- ts(usd$usd_index,\n            start = c(year(min(usd$Date)), 1),\n            frequency = 252)\n\nusd_df &lt;- data.frame(Date = usd$Date, Value = as.numeric(usd_ts))\n\nusd_df$MA50 &lt;- rollmean(usd_df$Value, 50, fill = NA, align = \"right\")\nusd_df$MA100 &lt;- rollmean(usd_df$Value, 100, fill = NA, align = \"right\")\nusd_df$MA200 &lt;- rollmean(usd_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(usd_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"USD Index\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"USD Index with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"USD Index\"))\n\n\n\n\n\n\n\n\n\n\nCode\nkospi_ts &lt;- ts(kospi$Close,\n            start = c(year(min(kospi$Date)), 1),\n            frequency = 252)\n\nkospi_df &lt;- data.frame(Date = kospi$Date, Value = as.numeric(kospi_ts))\n\nkospi_df$MA50 &lt;- rollmean(kospi_df$Value, 50, fill = NA, align = \"right\")\nkospi_df$MA100 &lt;- rollmean(kospi_df$Value, 100, fill = NA, align = \"right\")\nkospi_df$MA200 &lt;- rollmean(kospi_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(kospi_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"KOSPI\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"KOSPI Index with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"KOSPI\"))\n\n\n\n\n\n\n\n\n\n\nCode\nsp_ts &lt;- ts(sp500$Close,                                                \n             start = c(year(min(sp500$Date)), 1),\n            frequency = 252)                                              \nsp500_df &lt;- data.frame(Date = sp500$Date, Value = as.numeric(sp_ts))\n\nsp500_df$MA50 &lt;- rollmean(sp500_df$Value, 50, fill = NA, align = \"right\")\nsp500_df$MA100 &lt;- rollmean(sp500_df$Value, 100, fill = NA, align = \"right\")\nsp500_df$MA200 &lt;- rollmean(sp500_df$Value, 200, fill = NA, align = \"right\")\n\nplot_ly(sp500_df, x = ~Date) %&gt;%\n  add_lines(y = ~Value, name = \"S&P500\", line = list(color = \"black\")) %&gt;%\n  add_lines(y = ~MA50, name = \"MA50\", line = list(color = \"blue\")) %&gt;%\n  add_lines(y = ~MA100, name = \"MA100\", line = list(color = \"red\")) %&gt;%\n  add_lines(y = ~MA200, name = \"MA200\", line = list(color = \"green\")) %&gt;%\n  layout(title = \"S&P500 Index with Moving Averages\",\n         xaxis = list(title = \"Date\"),\n         yaxis = list(title = \"S&P500\"))\n\n\n\n\n\n\n\n\n\n\nSouth Korea base rate — MA3 / MA6 / MA12 MA3 hugs the policy path closely and shows every wiggle; good for short-term shifts but still choppy. MA6 trims a lot of the month-to-month noise and captures inflections earlier than MA12. MA12 is the smoothest but lags notably—during the 2024–25 jump it under-shoots the peak and turns later.\nFederal Funds rate — MA3 / MA6 / MA12 Same pattern: MA3 tracks near the target with small oscillations; MA6 balances smoothness with timely turns. MA12 best shows the multi-year regimes but reacts last to both the pandemic-era lift-off and the latest easing hints.\nKRW/USD spot — MA50 / MA100 / MA200 MA50 responds fastest to swings and gives earlier crossover signals but whipsaws more. MA100 is a middle road, filtering short bursts yet catching medium-term trends. MA200 is very stable, ideal for the long-run dollar trend versus KRW, but it will miss shorter cycles.\nKorea–US trade imports — MA12 / MA24 / MA36 MA12 preserves seasonal/short business-cycle movements and shows timing of surges and slowdowns best. MA24 reduces those oscillations and highlights the underlying climb. MA36 smooths heavily and is useful for long-horizon trend levels, at the cost of noticeable lag at turning points.\nKorea–US trade exports — MA12 / MA24 / MA36 MA12 captures export accelerations and dips quickly, helpful for monitoring momentum. MA24 dampens volatility and clarifies medium-term expansions. MA36 offers a clean structural trend but turns well after the fact in the 2020s cycle.\nUS–KR 3-year yield spread — MA50 / MA100 / MA200 MA50 reacts early to spread reversals and flags regime changes first, though it’s twitchier. MA100 stabilizes the shape and still picks up the 2020–25 upswing in good time. MA200 is the steadiest—great for high-level regime view—but late at both troughs and peaks.\nUS–KR 10-year yield spread — MA50 / MA100 / MA200 Similar trade-offs: MA50 is most responsive and catches shifts around the 2010s and mid-2020s quickly. MA100 smooths without losing medium-term timing. MA200 gives a slow, clear secular picture of narrowing then widening spreads with the most lag.\nSeoul housing index — MA12 / MA24 / MA36 MA12 spots the crest and rollover quickest in the early-2020s. MA24 offers a cleaner arc of the cycle, muting month-to-month noise. MA36 is very smooth but lates the post-peak stabilization, so better for policy/structural views than timing.\nUSD Index — MA50 / MA100 / MA200 MA50 catches tactical swings and crossover signals, but it flips more often. MA100 nicely summarizes medium-run trends. MA200 shows the secular dollar waves (’80s peak, 2000s rise, 2010s base) and is the least noisy, with the largest delay.\nKOSPI — MA50 / MA100 / MA200 MA50 is most sensitive—good for momentum but prone to whipsaw in selloffs/rebounds. MA100 cuts a lot of noise yet reacts within a reasonable window. MA200 defines bull/bear phases and major supports; excellent for long-term risk posture, slow for entries/exits."
  },
  {
    "objectID": "introduction/introduction.html",
    "href": "introduction/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Time series analyis in US economics influence on South korea’s economics\n1\nThe United States is the world’s largest economy and, in many ways, the bellwether of global finance. When U.S. economic or political events unfold—rate decisions, inflation surprises, policy shocks—markets everywhere react. Countries tightly connected to the U.S. through trade, capital flows, and technology supply chains feel these ripples most acutely.\nSouth Korea is a prime example. Its economy is deeply integrated with the U.S. through manufacturing-led exports, advanced technology industries, and financial linkages. U.S. shifts in growth, interest rates, and risk sentiment can quickly feed into Korea’s exchange rate, equity market, local interest rates, corporate financing conditions, and real activity. Korean policymakers and investors therefore watch the U.S. closely—adapting policy stances and portfolio strategies to absorb or harness these external forces.\nThis project explores how and how much U.S. ecomoics transmit to Korea’s economy and markets.This project focus on the dynamics : the channels of influence (rate differentials, dollar liquidity, risk appetite, growth signals), the speed and persistence of the effects, and how these relationships change across calm and stressed periods.\n\n\nbig picture\nThis project explores how—and how much—U.S. economic conditions transmit to Korea’s economy and markets. At the center of this transmission sits U.S. Treasuries: the world’s benchmark for risk-free returns. Treasury moves are not just bond-market trivia; they anchor global rates, funding costs, and the appetite for risk. When the U.S. curve shifts or policy guidance changes, the ripple travels quickly through the won–dollar exchange rate, Korean equities (KOSPI), local interest rates, and—after a lag—into the real economy via trade flows and housing markets. The project focuses on the dynamics: the channels of influence (rate differentials, dollar liquidity, risk appetite, growth signals), the speed and persistence of the effects, and how these relationships change across calm and stressed periods. By organizing evidence across foreign exchange, interest rates, equity markets, and real-side indicators, this analysis builds a coherent narrative of how U.S. financial conditions connect to Korean financial and economic outcomes.\n\n\n\nAnalytical Angels\n\nU.S. Rate Shocks & Channels\n\nU.S. Treasury moves embed changing views about Federal Reserve policy, inflation expectations, and growth momentum. Using the FRED Effective Federal Funds Rate and U.S. Treasury yield curves (3Y/10Y spreads), the project identifies how these shocks reach Korea through interest-rate differentials, dollar liquidity and risk sentiment shifts, and growth expectations—and when those channels amplify or offset one another.\n\nFX: Because foreign exchange sits at the center of global pricing and funding, the USD/KRW spot rate often reacts first to U.S. developments. We map when U.S. rate spikes strengthen the dollar and weaken the won, when those moves act as risk-off signals (tracked via the VIX volatility index and U.S. Dollar Index from Yahoo Finance), and how quickly—or slowly—the effects fade.\nKorean Yield Curve & Policy Response The Korean Treasury Bond (KTB) curve (3Y/10Y spreads) summarizes Korea’s sovereign borrowing costs and embedded growth/inflation expectations. We examine how shifts in the U.S. curve pass through to Korean yields, comparing movements in the Bank of Korea Base Rate with Fed policy to identify where transmission is sharp versus sticky, and how it differs across calm and stressed regimes. This reveals how much room Korean policymakers have to diverge from U.S. monetary policy without triggering destabilizing FX or capital flow pressures.\nEquities Equities translate rate information into valuations and earnings expectations. Using the KOSPI index alongside the S&P 500 and VIX for global risk context, we track how Korean equity performance responds to U.S. rate changes, spotlighting moments when stocks confirm the message from rates—or contradict it—revealing shifts in discount rates, growth optimism, and risk appetite across different market regimes.\n\nReal-Side Spillovers: Trade and Housing Financial impulses filter into activity with lags. We connect market shocks to Korea’s U.S. import/export volumes and the Korean residential property price index (Seoul metro area), clarifying when higher U.S. rates and a stronger dollar translate into softer trade momentum or tighter real-estate financing—and when resilience shows up instead. These real-economy linkages close the loop from financial transmission to tangible economic outcomes.\n\n\n\n\nGuiding Questions\n\nHow do U.S. Treasury yield changes transmit through Korea’s financial system (FX, rates, equities, credit)?\nWhat is the best way to identify a U.S. rate shock — event-day surprises, residualized yields, or structural VAR identification?\nWhat is the size of the pass-through elasticity between U.S. and Korean yields (e.g., dKTB3Y/dUST2Y, dKTB10Y/dUST10Y)?\nWhich Korean market reacts first and strongest to U.S. shocks, and what is the typical lag structure of these reactions?\nHow does the strength and speed of transmission vary across regimes — high VIX, Fed tightening cycles, or funding stress periods?\nDo FX, rate, and equity responses move consistently after shocks, or do they diverge (e.g., rates up, stocks steady)?\nHow do U.S. financial shocks spill over into Korea’s real economy — exports, industrial production, and housing — over time?\nAre U.S. rate hikes and cuts symmetric in their effects on Korea’s markets and economy?\nWhat share of Korea’s financial-market volatility is explained by U.S. shocks versus domestic or regional factors?\nWhat actionable signals should Korean policymakers and investors monitor — U.S. front-end policy, long-end term premium, or dollar liquidity indicators?\n\n\n\nLiterature reviews\n\nUS–Korea yield & rate\n\nRecent evidence shows US Treasury moves often lead other curves, with term-premium and expectations shocks radiating into global funding costs—consistent with the view that Korea’s KTB curve imports a sizable share of the US signal unless domestic policy/liquidity conditions push back (BIS, 2024)2. This motivates our decomposition of KTB moves into imported expectations vs local term-premium and our tests for wedge episodes when BoK priorities (growth/financial stability) resist external tightening.\n\nFX\n\nNew work from the Bank of Korea highlights the dollar’s outsized role in transmitting US financial shocks to small open economies, including Korea, via both trade invoicing and dollar funding channels (Bank of Korea, 2025)3. This supports our focus on mapping how US rate spikes strengthen the dollar, pressure the won, and cascade into local funding and asset prices—while testing state dependence (calm vs stressed) in the speed and persistence of KRW pass-through.\n\nEquities\n\nThe IMF’s 2025 Global Financial Stability Report documents elevated equity valuations alongside heightened sensitivity to rate and policy-uncertainty shocks, with correlations to long-rate moves rising in risk-on phases (IMF, 2025)4. This informs our approach to track when KOSPI co-moves with US equities and the dollar/risk complex—confirming the discount-rate channel—and when local earnings or sector dynamics generate divergence from the message embedded in rates.\n\nHousing market\n\nThe IMF’s 2024 Article IV for Korea, assesses housing affordability and interest-rate transmission, noting how tighter financial conditions and higher mortgage costs can weigh on transactions/prices even as some stabilization emerges (IMF, 2025)5. We use this to link imported rate/FX shocks to mortgage proxies, volumes, and prices, distinguishing quick volume effects from slower price adjustments and identifying thresholds where financing tightens materially.\n\nTrade\n\nBIS research after 2023 emphasizes valuation effects under dominant-currency pricing: exchange-rate swings reshape firms’ cash flows and can outweigh classic expenditure-switching in the short run (Nookhwun et al., 2025)6. This frames our tests of how USD strength and US–Korea rate spreads filter into Korea’s export receipts and import bills—and when strong US growth offsets FX/risk headwinds for volumes and pricing.\n\n\n\n\n\n\n\n\nReferences\n\n1. Https://www.bloomberg.com/news/articles/2025-05-14/us-korea-currency-talks-fuel-bets-trump-is-open-to-weaker-dollar.\n\n\n2. International Settlements, B. for. Investor optimism prevails over uncertainty. BIS Quarterly Review (2024).\n\n\n3. Bank of Korea, E. R. I. Dollar dominance and international spillovers of US financial shocks. https://www.bok.or.kr/imerEng/bbs/E0002902/list.do?menuNo=600342 (2025).\n\n\n4. Fund, I. M. Global financial stability report, april 2025: Chapter 1. https://www.imf.org/en/Publications/GFSR (2025).\n\n\n5. Fund, I. M. Republic of korea: 2024 article IV consultation—press release; staff report; and statement by the executive director. https://www.elibrary.imf.org/view/journals/002/2025/041/article-A001-en.xml (2025).\n\n\n6. Nookhwun, N. & coauthors. Exchange rate effects on firm performance: A NICER framework. https://www.bis.org/publ/work1266.pdf (2025)."
  },
  {
    "objectID": "about/about_me.html",
    "href": "about/about_me.html",
    "title": "About me",
    "section": "",
    "text": "Welcome to my website!!\nHi my name is Zoo un Park and i am a second year student in the Data science and Analytics program at Georgetown University. Originally from Seoul, South Korea, I graduated from University of Minnesota-Twin Cities in 2024 with a B.A. in statistics and a minor in management from University of Minnesota in 2024."
  },
  {
    "objectID": "about/about_me.html#myself",
    "href": "about/about_me.html#myself",
    "title": "About me",
    "section": "",
    "text": "Welcome to my website!!\nHi my name is Zoo un Park and i am a second year student in the Data science and Analytics program at Georgetown University. Originally from Seoul, South Korea, I graduated from University of Minnesota-Twin Cities in 2024 with a B.A. in statistics and a minor in management from University of Minnesota in 2024."
  },
  {
    "objectID": "about/about_me.html#academic-interest",
    "href": "about/about_me.html#academic-interest",
    "title": "About me",
    "section": "Academic interest",
    "text": "Academic interest\n\nBaseball Analytics\nFinancial Analysis( specifically investment strategy)\nDeep learning\nReinforce learning"
  },
  {
    "objectID": "data_viz/viz.html",
    "href": "data_viz/viz.html",
    "title": "Data Visualization",
    "section": "",
    "text": "Code\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(here)\nlibrary(lubridate)"
  },
  {
    "objectID": "data_viz/viz.html#exchange-rates",
    "href": "data_viz/viz.html#exchange-rates",
    "title": "Data Visualization",
    "section": "exchange rates",
    "text": "exchange rates\n                   \nInterest rate is a key fundamental index in country’s economics since it influences every economic field in the country. these two plots shows US and south korea interest rates. overall, south korea interest rate tends to follow U.S interest rate, most of the trend is very similar. notable part in two plots are after 2009 to 2015, which was after global economic crisis. U.S has cut interest rate close to zero, whereas south korea maintained its rate around 2-3%."
  },
  {
    "objectID": "ts/uni.html",
    "href": "ts/uni.html",
    "title": "Univariate TS Models(ARIMA/SARIMA)",
    "section": "",
    "text": "note\n\n\n\nIn the EDA part, there is stationary observed from ACF and PACF plot except seoul housing index. Also ADF test(after differencing) confirms this with significant low p-value. To check further specifically seoul housing index, first part of this section is performing second order differencing."
  },
  {
    "objectID": "ts/uni.html#model-choices",
    "href": "ts/uni.html#model-choices",
    "title": "Univariate TS Models(ARIMA/SARIMA)",
    "section": "Model choices",
    "text": "Model choices\n\nModel & Parameter selection (USD, KOSPI, and S&P500 are log-transformed before differencing.)\n\n\n\n\n\n\nSeries\nModel parameters\n\n\n\n\nSouth Korea base rate\nARIMA p = 0,1 d = 1 ,q = 0,1\n\n\nFED effective rate\nARIMA p = 0,1,2 , d = 0,1 , q = 0,1,2\n\n\nKRW/USD FX rate\nARIMA p = 0,1 d = 0,1 q = 0,1\n\n\nYield spread 3Y (US–KR)\nARIMA p = 0,1 d = 1 q = 0,1\n\n\nYield spread 10Y (US–KR)\nARIMA p = 0,1 d = 1 q = 0,1\n\n\nUSD index (log)\nARIMA p = 0,1 d = 1, , q = 0,1\n\n\nKOSPI index (log)\nARIMA p = 0,1 d = 1,q = 0,1,2\n\n\nS&P 500 index (log)\nARIMA p = 0,1 d = 0,1, q = 0,1\n\n\ntrade export KOR - USA\nSARIMA p = 0,1,d = 0,1 q = 0,1, P = 0,1,2,3 D = 0,1,Q = 0,1 , s= 12\n\n\ntrade import KOR -USA\nSARIMA p = 0,1,d = 0,1 q = 0,1, P = 0,1,2 D = 0,1,Q = 0,1, s = 12\n\n\nSeoul housing property index\nSARIMA p =0,1 ,d = 0,1,2 q = 0,1,2 P = 0,1, D = 0,1 ,Q = 0,1,2 ,s = 12"
  },
  {
    "objectID": "ts/uni.html#model-choicewith-equation",
    "href": "ts/uni.html#model-choicewith-equation",
    "title": "Univariate TS Models(ARIMA/SARIMA)",
    "section": "Model choice(with equation)",
    "text": "Model choice(with equation)\n\nSouth korea base rate\n\nModel : ARIMA(0,1,1)\n\\[\nEquation: x_t = 1.0000x_{t-1} + w_t + 0.0161w_{t-1}\n\\]\n\nFederal reserve rate\n\nModel: ARIMA(1,1,0)\n\\[\nEquation:\\; x_t = x_{t-1} + 0.6987(x_{t-1} - x_{t-2}) + 0.0229 + w_t\n\\]\n\nKRW/USD FX rate\n\nModel: ARIMA(1,0,1)\n\\[\nEquation:\\; x_t = 0.9997x_{t-1} + w_t + 0.0165w_{t-1} + 0.0011\n\\]\n\nUSA & South Korea yield spread rate(10Y)\n\nModel : ARIMA(1,0,1)\n\\[\nEquation:\\; x_t = 0.9968x_{t-1} + w_t - 0.0896w_{t-1} - 0.7027\n\\]\n\nUSD index\n\nModel: ARIMA(1,0,0)\n\\[\nEquation:\\; x_t = 0.9997x_{t-1} + 4.5713 + w_t\n\\]\n\nS&P500 index\n\nModel: ARIMA(0,1,1)\n\\[\nEquation:\\; x_t = x_{t-1} + 0.0003 + w_t - 0.0802w_{t-1}\n\\]\n\nKOSPI index\n\nModel : ARIMA(0,1,2)\n\\[\nEquation:\\; x_t = x_{t-1} + 0.0000 + w_t + 0.0258w_{t-1} - 0.0214w_{t-2}\n\\]\n\nTrade import South korea vs USA Model\n\nSARIMA(0,1,2)(0,1,1)[12]\n\\[\nEquation:\\; (1 - B)(1 - B^{12})x_t = (1 - 0.5291B + 0.1363B^2)(1 - 0.9351B^{12})w_t\n\\]\n\nTrade import South korea vs USA\n\nModel : SARIMA(0,1,1)(0,1,1)[12]\n\\[\nModel : SARIMA(0,1,1)(0,1,1)[12] \\\nEquation:\\; (1 - B)(1 - B^{12})x_t = (1 - 0.5536B)(1 - 0.8441B^{12})w_t\n\\]\n\nSeoul housing property index\n\nModel : SARIMA(1,1,2)(0,1,1)[12]\n\\[\nEquation:\\; (1 - 0.7799B)(1 - B)(1 - B^{12})x_t = (1 + 0.2868B + 0.1734B^2)(1 - 0.9998B^{12})w_t\n\\]"
  },
  {
    "objectID": "ts/multi.html",
    "href": "ts/multi.html",
    "title": "Multivariate TS Models(ARIMAX/SARIMAX/VAR)",
    "section": "",
    "text": "note\n\n\n\nthere are three models, but more models will be added\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(zoo)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(readr)\nlibrary(kableExtra)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(vars)\nlibrary(here)\nlibrary(tsibble)\nlibrary(dplyr)\n# calling data\n\n#KR base rate\nbok&lt;- read.csv(\"../data/interest/bok.csv\")%&gt;%\n  rename(Date = date)\nbok$Date&lt;- as.Date(bok$Date)\nbok &lt;- bok %&gt;%\n  mutate(Date = floor_date(Date, unit = \"quarter\")) %&gt;%\n  group_by(Date) %&gt;%\n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = \"drop\")\n\n\n# FED rate \n\nusr&lt;- read.csv(\"../data/interest/us_rate.csv\")%&gt;%\n  rename(Date = observation_date,rate = DFF)\nusr$Date&lt;- as.Date(usr$Date)\nusr&lt;- usr %&gt;%\n  mutate(Date = floor_date(Date, unit = \"quarter\")) %&gt;%\n  group_by(Date) %&gt;%\n  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)), .groups = \"drop\")\n\n# KRW/USD rate\n\nkr &lt;- read.csv(\"../data/fx rate/kor.csv\")\nkr &lt;- kr %&gt;%\n  transmute(\n    Date = as.Date(observation_date),\n    krw  = DEXKOUS,    \n    usd  = 1 / DEXKOUS  \n  ) %&gt;%\n  filter(!is.na(Date)) %&gt;%\n  arrange(Date) %&gt;%\n  distinct(Date, .keep_all = TRUE) %&gt;%\n  complete(Date = seq(min(Date), max(Date), by = \"day\")) %&gt;%\n\n  fill(krw, usd, .direction = \"down\")\n\n\n# USD index \n\nusd &lt;- read_csv(\"../data/fx rate/usd_index.csv\", show_col_types = FALSE)\nusd &lt;- usd %&gt;%\n  transmute(\n    Date = as.Date(Date),\n    usd_index = Close\n  ) %&gt;%\n  filter(!is.na(Date)) %&gt;%\n  arrange(Date) %&gt;%\n  distinct(Date, .keep_all = TRUE) %&gt;%\n  complete(Date = seq(min(Date), max(Date), by = \"day\")) %&gt;%\n  fill(usd_index, .direction = \"down\")\n\n\n\n# Seoul housing data\n\nhousing &lt;- read_csv(here(\"data/housing/house.csv\")) %&gt;%\n  mutate(Date = as.Date(Date))\n\nhousing &lt;- housing %&gt;% mutate(Date = as.Date(Date))\n\n\n# Yield data \n\nus_yield  &lt;- read.csv(here(\"data/yield\", \"us_yield.csv\"))\nkor_yield   &lt;- read.csv(here(\"data/yield\", \"kor_yield.csv\"))\n\n\nus_yield$Date  &lt;- as.Date(us_yield$Date)\nkor_yield$Date &lt;- as.Date(kor_yield$Date)\n\ncolnames(us_yield)[colnames(us_yield)  == \"X3Y\"]  &lt;- \"US_3Y\"\ncolnames(us_yield)[colnames(us_yield)  == \"X10Y\"] &lt;- \"US_10Y\"\ncolnames(kor_yield)[colnames(kor_yield) == \"X3Y\"]  &lt;- \"KR_3Y\"\ncolnames(kor_yield)[colnames(kor_yield) == \"X10Y\"] &lt;- \"KR_10Y\"\n\nus_yield  &lt;- us_yield[,  c(\"Date\", \"US_3Y\", \"US_10Y\")]\nkor_yield &lt;- kor_yield[, c(\"Date\", \"KR_3Y\", \"KR_10Y\")]\n\nus_yield  &lt;- us_yield  %&gt;% arrange(Date) %&gt;% fill(US_3Y, US_10Y, .direction = \"down\")\nkor_yield &lt;- kor_yield %&gt;% arrange(Date) %&gt;% fill(KR_3Y, KR_10Y, .direction = \"down\")\n\n\ndf &lt;- merge(us_yield, kor_yield, by = \"Date\")\n\ndf$US_3m10  &lt;- df$US_3Y - df$US_10Y\ndf$KR_3m10  &lt;- df$KR_3Y - df$KR_10Y\ndf$US_KR_3Y &lt;- df$US_3Y - df$KR_3Y\ndf$US_KR_10Y&lt;- df$US_10Y - df$KR_10Y\n\n\n#import & export data \n\nimports &lt;- read_csv(here::here(\"data/trade\", \"imports.csv\"))\nexports &lt;- read_csv(here::here(\"data/trade\", \"exports.csv\"))\n\nclean_date &lt;- function(x) {\n  as.Date(paste0(sub(\"^([0-9]{4})([0-9]{2})$\", \"\\\\1-\\\\2\", gsub(\"/\", \"-\", as.character(x))), \"-01\"))\n}\n\nimports &lt;- imports %&gt;%\n  mutate(Date = clean_date(Date),\n         Type = \"Imports\")\n\nexports &lt;- exports %&gt;%\n  mutate(Date = clean_date(Date),\n         Type = \"Exports\")\ntrade &lt;- bind_rows(imports, exports)\n\nnames(trade)[2] &lt;- \"Value\"\n\ntrade_ts &lt;- trade %&gt;%\n  as_tsibble(index = Date, key = Type)\n\n\n# S&P500 data\nsp500 &lt;- read_csv(\"../data/stock/sp500.csv\")\n\n\n# KOSPI data\nkospi &lt;- read_csv(\"../data/stock/kospi.csv\")\nkospi$Date &lt;- as.Date(kospi$Date)\n\n# VIX data(added for the modeling)\nvix&lt;- read_csv(\"../data/stock/vix.csv\")%&gt;%\n  mutate(Date = ymd(Date)) %&gt;%\n  arrange(Date) %&gt;%\n  fill(vix, .direction = \"down\")\n\n\n# extract spreads from df\n\n\nus_spreads &lt;- df %&gt;%\n  dplyr::select(Date, US_3m10) %&gt;%\n  rename(us_spread = US_3m10) %&gt;%\n  mutate(Date = as.Date(Date))\n\nkor_spreads &lt;- df %&gt;%\n  dplyr::select(Date, KR_3m10) %&gt;%\n  rename(kr_spread = KR_3m10) %&gt;%\n  mutate(Date = as.Date(Date))\n\nus_kr_spreads_3y &lt;- df %&gt;%\n  dplyr::select(Date, US_KR_3Y) %&gt;%\n  mutate(Date = as.Date(Date))\n\nus_kr_spreads_10y &lt;- df %&gt;%\n  dplyr::select(Date, US_KR_10Y) %&gt;%\n  mutate(Date = as.Date(Date))\n\n\n\nModels arimax:\n\n\nkorea yield spread rate ~ us yield spread rate+ us ffr+ bok rate\nrate difference & FX: USD/KRW spot rate ~ us-korea spread rate 3years+ us-korea spread rate 3years+ S&P500 + dollar index\n\nvar:\n\nequity: s&p500, us_yield_spread,KOSPI index\ntrade : KR_exports, usd index, usd/krw spot rate\n\n\nVAR model\n\nequity: s&p500, vix, us_yield_spread,KOSPI index\n\ntime series plotparameter selectionmodel summaryCVforecast\n\n\n\n\nCode\nlibrary(dplyr)\ndf1 &lt;- us_spreads %&gt;%\n   left_join(sp500, by = \"Date\") %&gt;%\n   left_join(kospi, by = \"Date\")%&gt;%\n   dplyr::select(Date, us_spread, close_sp500 = Close.x , close_kospi = Close.y)%&gt;%\n   arrange(Date) %&gt;%\n   fill(close_sp500,close_kospi, .direction = \"down\")\n \ndf1$log_kospi&lt;- log(df1$close_kospi)\ndf1$log_sp500&lt;- log(df1$close_sp500)\n\n\n start_year_df1  &lt;- year(min(df1$Date))\n start_month_df1 &lt;- month(min(df1$Date))\n\n\np1 &lt;- plot_ly(df1, x = ~Date, y = ~us_spread, type = 'scatter', mode = 'lines',\n              name = \"U.S Spread Rate\") %&gt;%\n  layout(yaxis = list(title = \"U.S Spread Rate\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\np2 &lt;- plot_ly(df1, x = ~Date, y = ~log_sp500, type = 'scatter', mode = 'lines',\n              name = \"S&P500 Index(log)\") %&gt;%\n  layout(yaxis = list(title = \"S&P500 Index(log)\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\np3 &lt;- plot_ly(df1, x = ~Date, y = ~log_kospi, type = 'scatter', mode = 'lines',\n              name = \"KOSPI Index(log)\") %&gt;%\n  layout(yaxis = list(title = \"KOSPI Index(log)\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\nsubplot(p1, p2, p3, nrows = 3, shareX = TRUE, titleX = TRUE) %&gt;%\n  layout(title = list(text = \"Equities:KOSPI index, S&P 500 index, U.S T-bond spread rate\", font = list(size = 18)),\n         margin = list(l = 70, r = 40, t = 60, b = 40))\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df1&lt;- df1[,c(2,5,6)]\ndf1.ts&lt;-ts(new_df1,star=decimal_date(as.Date(\"2001-12-01\",format = \"%Y-%m-%d\")),frequency = 252)\nVARselect(df1.ts, lag.max=10, type=\"both\")\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n    10      5      2     10 \n\n$criteria\n                   1             2             3             4             5\nAIC(n) -2.419658e+01 -2.436948e+01 -2.437841e+01 -2.438541e+01 -2.438900e+01\nHQ(n)  -2.419068e+01 -2.436005e+01 -2.436544e+01 -2.436890e+01 -2.436895e+01\nSC(n)  -2.417962e+01 -2.434234e+01 -2.434109e+01 -2.433791e+01 -2.433132e+01\nFPE(n)  3.101405e-11  2.608965e-11  2.585770e-11  2.567740e-11  2.558543e-11\n                   6             7             8             9            10\nAIC(n) -2.439247e+01 -2.439309e+01 -2.439656e+01 -2.440048e+01 -2.440168e+01\nHQ(n)  -2.436889e+01 -2.436597e+01 -2.436590e+01 -2.436628e+01 -2.436394e+01\nSC(n)  -2.432461e+01 -2.431505e+01 -2.430834e+01 -2.430208e+01 -2.429310e+01\nFPE(n)  2.549667e-11  2.548083e-11  2.539261e-11  2.529342e-11  2.526311e-11\n\n\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=2, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5918 \nLog Likelihood: 46927.097 \nRoots of the characteristic polynomial:\n0.9987 0.9979 0.9954 0.2162 0.0273 0.0273\nCall:\nVAR(y = new_df1, p = 2, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  1.005e+00  1.302e-02  77.209   &lt;2e-16 ***\nlog_kospi.l1  4.318e-02  3.263e-02   1.324    0.186    \nlog_sp500.l1  5.690e-02  3.593e-02   1.583    0.113    \nus_spread.l2 -7.440e-03  1.302e-02  -0.572    0.568    \nlog_kospi.l2 -4.234e-02  3.264e-02  -1.297    0.195    \nlog_sp500.l2 -5.388e-02  3.591e-02  -1.501    0.134    \nconst        -2.991e-02  2.686e-02  -1.114    0.265    \ntrend        -4.247e-07  1.078e-06  -0.394    0.694    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03353 on 5910 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 4.428e+05 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  4.210e-03  4.990e-03   0.844   0.3989    \nlog_kospi.l1  9.266e-01  1.250e-02  74.106  &lt; 2e-16 ***\nlog_sp500.l1  3.906e-01  1.377e-02  28.365  &lt; 2e-16 ***\nus_spread.l2 -4.170e-03  4.989e-03  -0.836   0.4032    \nlog_kospi.l2  7.104e-02  1.251e-02   5.679 1.42e-08 ***\nlog_sp500.l2 -3.907e-01  1.376e-02 -28.390  &lt; 2e-16 ***\nconst         1.698e-02  1.029e-02   1.650   0.0991 .  \ntrend         4.458e-07  4.131e-07   1.079   0.2805    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01285 on 5910 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 1.081e+06 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1 -7.316e-03  4.799e-03  -1.524 0.127492    \nlog_kospi.l1  3.228e-02  1.203e-02   2.684 0.007286 ** \nlog_sp500.l1  8.753e-01  1.324e-02  66.083  &lt; 2e-16 ***\nus_spread.l2  7.526e-03  4.798e-03   1.569 0.116796    \nlog_kospi.l2 -3.438e-02  1.203e-02  -2.858 0.004284 ** \nlog_sp500.l2  1.215e-01  1.324e-02   9.183  &lt; 2e-16 ***\nconst         3.540e-02  9.900e-03   3.576 0.000352 ***\ntrend         1.609e-06  3.973e-07   4.049  5.2e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01236 on 5910 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 1.748e+06 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread log_kospi  log_sp500\nus_spread  1.124e-03 1.530e-06 -1.898e-05\nlog_kospi  1.530e-06 1.651e-04  4.392e-05\nlog_sp500 -1.898e-05 4.392e-05  1.527e-04\n\nCorrelation matrix of residuals:\n          us_spread log_kospi log_sp500\nus_spread  1.000000  0.003551  -0.04582\nlog_kospi  0.003551  1.000000   0.27658\nlog_sp500 -0.045820  0.276579   1.00000\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=5, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5915 \nLog Likelihood: 46994.576 \nRoots of the characteristic polynomial:\n0.9989 0.9983 0.9951 0.5204 0.5204 0.5144 0.5144 0.4234 0.4111 0.4111 0.3816 0.3816 0.373 0.373 0.2981\nCall:\nVAR(y = new_df1, p = 5, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  1.002e+00  1.301e-02  77.017  &lt; 2e-16 ***\nlog_kospi.l1  1.256e-02  3.563e-02   0.352 0.724478    \nlog_sp500.l1  6.579e-02  3.675e-02   1.790 0.073477 .  \nus_spread.l2  8.197e-04  1.843e-02   0.044 0.964530    \nlog_kospi.l2 -3.401e-02  4.707e-02  -0.723 0.469980    \nlog_sp500.l2 -9.580e-03  4.836e-02  -0.198 0.842991    \nus_spread.l3 -2.020e-02  1.843e-02  -1.096 0.273182    \nlog_kospi.l3  2.201e-02  4.719e-02   0.466 0.640900    \nlog_sp500.l3  6.182e-02  4.972e-02   1.243 0.213783    \nus_spread.l4 -1.204e-02  1.843e-02  -0.653 0.513772    \nlog_kospi.l4  2.331e-02  4.615e-02   0.505 0.613522    \nlog_sp500.l4  2.283e-02  4.924e-02   0.464 0.642863    \nus_spread.l5  2.717e-02  1.300e-02   2.089 0.036755 *  \nlog_kospi.l5 -2.352e-02  3.276e-02  -0.718 0.472758    \nlog_sp500.l5 -1.388e-01  3.949e-02  -3.515 0.000443 ***\nconst        -1.963e-02  2.694e-02  -0.729 0.466262    \ntrend        -1.036e-07  1.081e-06  -0.096 0.923694    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03347 on 5898 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 1.942e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  3.449e-03  4.950e-03   0.697   0.4860    \nlog_kospi.l1  8.749e-01  1.355e-02  64.561  &lt; 2e-16 ***\nlog_sp500.l1  4.162e-01  1.398e-02  29.779  &lt; 2e-16 ***\nus_spread.l2 -9.057e-03  7.010e-03  -1.292   0.1964    \nlog_kospi.l2  7.212e-02  1.790e-02   4.028 5.69e-05 ***\nlog_sp500.l2 -2.779e-01  1.839e-02 -15.106  &lt; 2e-16 ***\nus_spread.l3  2.893e-03  7.010e-03   0.413   0.6798    \nlog_kospi.l3  2.295e-02  1.795e-02   1.279   0.2010    \nlog_sp500.l3 -2.757e-02  1.891e-02  -1.458   0.1449    \nus_spread.l4  2.902e-03  7.011e-03   0.414   0.6790    \nlog_kospi.l4  1.520e-02  1.755e-02   0.866   0.3866    \nlog_sp500.l4 -8.148e-02  1.873e-02  -4.351 1.38e-05 ***\nus_spread.l5  2.195e-05  4.946e-03   0.004   0.9965    \nlog_kospi.l5  1.240e-02  1.246e-02   0.995   0.3197    \nlog_sp500.l5 -2.974e-02  1.502e-02  -1.980   0.0477 *  \nconst         2.053e-02  1.024e-02   2.004   0.0451 *  \ntrend         4.817e-07  4.112e-07   1.172   0.2414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01273 on 5898 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 4.801e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1 -6.714e-03  4.799e-03  -1.399 0.161845    \nlog_kospi.l1  3.661e-02  1.314e-02   2.787 0.005344 ** \nlog_sp500.l1  8.733e-01  1.355e-02  64.448  &lt; 2e-16 ***\nus_spread.l2  3.149e-03  6.797e-03   0.463 0.643122    \nlog_kospi.l2 -4.948e-02  1.736e-02  -2.851 0.004378 ** \nlog_sp500.l2  1.165e-01  1.783e-02   6.533 7.00e-11 ***\nus_spread.l3  3.961e-03  6.796e-03   0.583 0.560010    \nlog_kospi.l3  1.150e-02  1.740e-02   0.661 0.508860    \nlog_sp500.l3  2.171e-02  1.833e-02   1.184 0.236461    \nus_spread.l4  1.208e-02  6.797e-03   1.777 0.075545 .  \nlog_kospi.l4  1.366e-02  1.702e-02   0.803 0.422232    \nlog_sp500.l4 -4.602e-02  1.816e-02  -2.535 0.011276 *  \nus_spread.l5 -1.230e-02  4.795e-03  -2.564 0.010364 *  \nlog_kospi.l5 -1.436e-02  1.208e-02  -1.189 0.234606    \nlog_sp500.l5  3.140e-02  1.456e-02   2.156 0.031122 *  \nconst         3.451e-02  9.932e-03   3.474 0.000516 ***\ntrend         1.580e-06  3.986e-07   3.963 7.49e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01234 on 5898 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 7.667e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread  log_kospi  log_sp500\nus_spread  1.120e-03 -4.196e-07 -1.812e-05\nlog_kospi -4.196e-07  1.620e-04  4.394e-05\nlog_sp500 -1.812e-05  4.394e-05  1.523e-04\n\nCorrelation matrix of residuals:\n           us_spread  log_kospi log_sp500\nus_spread  1.0000000 -0.0009848  -0.04386\nlog_kospi -0.0009848  1.0000000   0.27970\nlog_sp500 -0.0438603  0.2797035   1.00000\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=10, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5910 \nLog Likelihood: 47045.173 \nRoots of the characteristic polynomial:\n0.999 0.9984 0.9951 0.7704 0.7704 0.7486 0.7486 0.7463 0.7463 0.7041 0.7041 0.6959 0.6895 0.6895 0.6807 0.6807 0.6722 0.6554 0.6554 0.6546 0.6546 0.6301 0.6301 0.601 0.601 0.5982 0.5982 0.4709 0.4588 0.3093\nCall:\nVAR(y = new_df1, p = 10, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1   1.002e+00  1.305e-02  76.749  &lt; 2e-16 ***\nlog_kospi.l1   3.737e-03  3.569e-02   0.105 0.916600    \nlog_sp500.l1   6.888e-02  3.692e-02   1.866 0.062132 .  \nus_spread.l2   1.230e-03  1.846e-02   0.067 0.946885    \nlog_kospi.l2  -3.245e-02  4.708e-02  -0.689 0.490682    \nlog_sp500.l2   6.665e-05  4.857e-02   0.001 0.998905    \nus_spread.l3  -1.983e-02  1.843e-02  -1.076 0.282071    \nlog_kospi.l3   2.075e-02  4.720e-02   0.440 0.660182    \nlog_sp500.l3   5.134e-02  4.989e-02   1.029 0.303429    \nus_spread.l4  -1.334e-02  1.841e-02  -0.725 0.468652    \nlog_kospi.l4  -7.511e-04  4.720e-02  -0.016 0.987305    \nlog_sp500.l4   4.288e-02  4.984e-02   0.860 0.389668    \nus_spread.l5   9.839e-04  1.841e-02   0.053 0.957376    \nlog_kospi.l5  -6.118e-02  4.718e-02  -1.297 0.194734    \nlog_sp500.l5  -6.796e-02  4.989e-02  -1.362 0.173150    \nus_spread.l6   1.159e-02  1.840e-02   0.629 0.529055    \nlog_kospi.l6   1.586e-01  4.722e-02   3.359 0.000786 ***\nlog_sp500.l6  -6.364e-02  4.981e-02  -1.278 0.201468    \nus_spread.l7   2.156e-02  1.841e-02   1.171 0.241726    \nlog_kospi.l7  -1.830e-02  4.724e-02  -0.387 0.698491    \nlog_sp500.l7  -1.358e-01  4.980e-02  -2.727 0.006407 ** \nus_spread.l8   3.135e-03  1.842e-02   0.170 0.864816    \nlog_kospi.l8  -5.057e-02  4.724e-02  -1.071 0.284413    \nlog_sp500.l8   1.883e-01  4.983e-02   3.778 0.000159 ***\nus_spread.l9  -1.267e-02  1.844e-02  -0.687 0.492146    \nlog_kospi.l9  -7.425e-02  4.621e-02  -1.607 0.108167    \nlog_sp500.l9  -9.591e-02  4.943e-02  -1.940 0.052404 .  \nus_spread.l10  4.044e-03  1.302e-02   0.311 0.756052    \nlog_kospi.l10  5.440e-02  3.283e-02   1.657 0.097623 .  \nlog_sp500.l10  1.349e-02  3.967e-02   0.340 0.733836    \nconst         -1.445e-02  2.705e-02  -0.534 0.593179    \ntrend          3.707e-08  1.086e-06   0.034 0.972763    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03338 on 5878 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 1.007e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1   3.823e-03  4.961e-03   0.770  0.44105    \nlog_kospi.l1   8.713e-01  1.357e-02  64.213  &lt; 2e-16 ***\nlog_sp500.l1   4.219e-01  1.404e-02  30.057  &lt; 2e-16 ***\nus_spread.l2  -1.007e-02  7.018e-03  -1.435  0.15138    \nlog_kospi.l2   7.196e-02  1.790e-02   4.021 5.88e-05 ***\nlog_sp500.l2  -2.801e-01  1.847e-02 -15.166  &lt; 2e-16 ***\nus_spread.l3   2.181e-03  7.007e-03   0.311  0.75564    \nlog_kospi.l3   2.189e-02  1.794e-02   1.220  0.22256    \nlog_sp500.l3  -2.711e-02  1.897e-02  -1.429  0.15294    \nus_spread.l4   3.345e-03  7.000e-03   0.478  0.63279    \nlog_kospi.l4   6.615e-03  1.795e-02   0.369  0.71247    \nlog_sp500.l4  -7.452e-02  1.895e-02  -3.932 8.53e-05 ***\nus_spread.l5  -8.468e-03  6.999e-03  -1.210  0.22639    \nlog_kospi.l5  -1.493e-02  1.794e-02  -0.832  0.40531    \nlog_sp500.l5  -1.364e-02  1.897e-02  -0.719  0.47203    \nus_spread.l6   1.404e-02  6.997e-03   2.007  0.04483 *  \nlog_kospi.l6   4.627e-02  1.795e-02   2.577  0.00998 ** \nlog_sp500.l6  -1.438e-02  1.894e-02  -0.759  0.44783    \nus_spread.l7  -2.637e-03  7.000e-03  -0.377  0.70636    \nlog_kospi.l7  -1.601e-02  1.796e-02  -0.892  0.37269    \nlog_sp500.l7   3.496e-02  1.893e-02   1.846  0.06490 .  \nus_spread.l8   6.284e-03  7.002e-03   0.898  0.36947    \nlog_kospi.l8  -1.374e-02  1.796e-02  -0.765  0.44418    \nlog_sp500.l8   1.423e-02  1.895e-02   0.751  0.45251    \nus_spread.l9  -1.457e-02  7.010e-03  -2.078  0.03772 *  \nlog_kospi.l9   4.660e-02  1.757e-02   2.652  0.00802 ** \nlog_sp500.l9  -3.879e-02  1.880e-02  -2.064  0.03907 *  \nus_spread.l10  6.351e-03  4.949e-03   1.283  0.19941    \nlog_kospi.l10 -2.255e-02  1.248e-02  -1.806  0.07090 .  \nlog_sp500.l10 -2.325e-02  1.508e-02  -1.541  0.12326    \nconst          2.347e-02  1.029e-02   2.282  0.02253 *  \ntrend          5.469e-07  4.128e-07   1.325  0.18527    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01269 on 5878 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 2.479e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  -5.799e-03  4.795e-03  -1.209 0.226579    \nlog_kospi.l1   3.762e-02  1.311e-02   2.868 0.004143 ** \nlog_sp500.l1   8.775e-01  1.357e-02  64.678  &lt; 2e-16 ***\nus_spread.l2   3.384e-03  6.783e-03   0.499 0.617871    \nlog_kospi.l2  -5.056e-02  1.730e-02  -2.922 0.003486 ** \nlog_sp500.l2   1.102e-01  1.785e-02   6.173 7.13e-10 ***\nus_spread.l3   1.698e-03  6.773e-03   0.251 0.802102    \nlog_kospi.l3   1.404e-02  1.734e-02   0.809 0.418430    \nlog_sp500.l3   2.354e-02  1.833e-02   1.284 0.199261    \nus_spread.l4   1.370e-02  6.766e-03   2.025 0.042940 *  \nlog_kospi.l4   1.411e-02  1.735e-02   0.814 0.415946    \nlog_sp500.l4  -4.545e-02  1.832e-02  -2.481 0.013127 *  \nus_spread.l5  -7.747e-03  6.765e-03  -1.145 0.252170    \nlog_kospi.l5  -5.645e-02  1.734e-02  -3.256 0.001136 ** \nlog_sp500.l5   1.783e-02  1.833e-02   0.973 0.330697    \nus_spread.l6  -9.871e-04  6.763e-03  -0.146 0.883962    \nlog_kospi.l6   3.333e-02  1.735e-02   1.921 0.054797 .  \nlog_sp500.l6  -1.365e-02  1.831e-02  -0.746 0.455959    \nus_spread.l7  -1.439e-02  6.766e-03  -2.127 0.033500 *  \nlog_kospi.l7  -1.557e-02  1.736e-02  -0.897 0.369785    \nlog_sp500.l7   8.217e-02  1.830e-02   4.490 7.26e-06 ***\nus_spread.l8   2.489e-02  6.768e-03   3.678 0.000237 ***\nlog_kospi.l8  -2.296e-02  1.736e-02  -1.323 0.186001    \nlog_sp500.l8  -4.501e-02  1.831e-02  -2.458 0.014006 *  \nus_spread.l9  -1.923e-02  6.775e-03  -2.838 0.004551 ** \nlog_kospi.l9   8.825e-02  1.698e-02   5.197 2.09e-07 ***\nlog_sp500.l9   4.684e-03  1.817e-02   0.258 0.796531    \nus_spread.l10  4.649e-03  4.783e-03   0.972 0.331154    \nlog_kospi.l10 -4.380e-02  1.207e-02  -3.630 0.000286 ***\nlog_sp500.l10 -1.467e-02  1.458e-02  -1.006 0.314295    \nconst          3.262e-02  9.941e-03   3.281 0.001040 ** \ntrend          1.486e-06  3.990e-07   3.724 0.000198 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01227 on 5878 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 4.005e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread  log_kospi  log_sp500\nus_spread  1.114e-03 -1.219e-06 -1.667e-05\nlog_kospi -1.219e-06  1.611e-04  4.338e-05\nlog_sp500 -1.667e-05  4.338e-05  1.505e-04\n\nCorrelation matrix of residuals:\n          us_spread log_kospi log_sp500\nus_spread  1.000000 -0.002877  -0.04071\nlog_kospi -0.002877  1.000000   0.27864\nlog_sp500 -0.040713  0.278642   1.00000\n\n\n\n\n\n\nCode\nn=length(df1$log_sp500) \nk=1480 #1480\n#n-k=4440; 4440/252=17.619\nrmse1 &lt;- matrix(NA, 4440,3) #here 4440 is n-k\nrmse2 &lt;- matrix(NA, 4440,3)\nrmse3 &lt;- matrix(NA,4440,3) #here n-k / 252 = 4440/252 =17.619\nyear&lt;-c()\nts_obj &lt;- ts(df1[, c(2,5,6)], start=decimal_date(as.Date(\"2000-12-18\",format = \"%Y-%m-%d\")),frequency = 252)\nst &lt;- tsp(ts_obj)[1]+(k-1)/252 \nfor(i in 1:17) #here 17 is (n-k ) / 252 = 4440/252 =17.619\n{\n  \n  xtrain &lt;- window(ts_obj, end=st + i-1)\n  xtest &lt;- window(ts_obj, start=st + (i-1) + 1/252, end=st + i)\n  \n  # first model p = 2 \n  fit &lt;- vars::VAR(xtrain, p=2, type='both')\n  fcast &lt;- predict(fit, n.ahead = 252)\n  \n  fspread&lt;-fcast$fcst$us_spread\n  fkospi&lt;-fcast$fcst$log_kospi\n  fsp&lt;-fcast$fcst$log_sp500\n  \n  ff1&lt;-data.frame(fspread[,1],fkospi[,1],fsp[,1]) \n  year&lt;-st + (i-1) + 1/252 \n  \n  \n  ff1&lt;-ts(ff1,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251 \n  b= 252*i \n \n  rmse1[c(a:b),]  &lt;-sqrt((ff1-xtest)^2)\n  \n  #second model p = 5\n  fit2 &lt;- vars::VAR(xtrain, p=5, type='both')\n  fcast2 &lt;- predict(fit2, n.ahead = 252)\n  \n  fspread2&lt;-fcast2$fcst$us_spread\n  fkospi2&lt;-fcast2$fcst$log_kospi\n  fsp2&lt;-fcast2$fcst$log_sp500\n  ff2&lt;-data.frame(fspread2[,1],fkospi2[,1],fsp2[,1])\n  \n  year&lt;-st + (i-1) + 1/252\n  \n  ff2&lt;-ts(ff2,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251\n  b= 252*i\n  rmse2[c(a:b),]  &lt;-sqrt((ff2-xtest)^2)\n  \n  #third model p = 10\n  fit3 &lt;- vars::VAR(xtrain, p=10, type='both')\n  fcast3 &lt;- predict(fit3, n.ahead = 252)\n  \n  fspread3&lt;-fcast3$fcst$us_spread\n  fkospi3&lt;-fcast3$fcst$log_kospi\n  fsp3&lt;-fcast3$fcst$log_sp500\n  ff3&lt;-data.frame(fspread3[,1],fkospi3[,1],fsp3[,1])\n  \n  year&lt;-st + (i-1) + 1/252\n  \n  ff3&lt;-ts(ff3,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251\n  b= 252*i\n  rmse3[c(a:b),]  &lt;-sqrt((ff3-xtest)^2)\n}\n\n\n\n\nCode\nday_index = 1:4440\ndates1 = as.Date(df1$Date[(k+1):n])\nrmse1 = data.frame(day_index,dates1,rmse1)\nnames(rmse1) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse2 = data.frame(day_index,dates1,rmse2)\nnames(rmse2) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse3 = data.frame(day_index,dates1,rmse3)\nnames(rmse3) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse1$Model &lt;- \"VAR(2)\"\nrmse2$Model &lt;- \"VAR(5)\"\nrmse3$Model &lt;- \"VAR(10)\"\nrmse_combined &lt;- rbind(rmse1, rmse2, rmse3)\nrmse1$Model &lt;- \"VAR(2)\"\nrmse2$Model &lt;- \"VAR(5)\"\nrmse3$Model &lt;- \"VAR(10)\"\nrmse_combined &lt;- rbind(rmse1, rmse2, rmse3)\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = log_kospi, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for log_kospi\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = log_sp500, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for log_sp500\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = us_spread, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for us_spread\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(vars)\nlibrary(forecast)\nlibrary(plotly)\n\n# Fit VAR(5) on full data\nvar5 &lt;- VAR(ts_obj, p = 5, type = \"both\")\n\n# Forecast 252 days ahead\nh &lt;- 504\nfcast &lt;- forecast(var5, h = h)\n\n# us_spread plot (not log-transformed, keep as is)\nfig1 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"us_spread\"], 2500))), \n            y = as.numeric(tail(ts_obj[, \"us_spread\"], 2500)), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n            y = as.numeric(fcast$forecast$us_spread$mean), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n              ymin = as.numeric(fcast$forecast$us_spread$lower[,2]), \n              ymax = as.numeric(fcast$forecast$us_spread$upper[,2]),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n              ymin = as.numeric(fcast$forecast$us_spread$lower[,1]), \n              ymax = as.numeric(fcast$forecast$us_spread$upper[,1]),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for us_spread\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"us_spread\"),\n         hovermode = \"x unified\")\n\n# KOSPI plot (transform back from log to original scale)\nfig2 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"log_kospi\"], 2500))), \n            y = exp(as.numeric(tail(ts_obj[, \"log_kospi\"], 2500))), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n            y = exp(as.numeric(fcast$forecast$log_kospi$mean)), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_kospi$lower[,2])), \n              ymax = exp(as.numeric(fcast$forecast$log_kospi$upper[,2])),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_kospi$lower[,1])), \n              ymax = exp(as.numeric(fcast$forecast$log_kospi$upper[,1])),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for KOSPI\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"KOSPI\"),\n         hovermode = \"x unified\")\n\n# S&P500 plot (transform back from log to original scale)\nfig3 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"log_sp500\"], 2500))), \n            y = exp(as.numeric(tail(ts_obj[, \"log_sp500\"], 2500))), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n            y = exp(as.numeric(fcast$forecast$log_sp500$mean)), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_sp500$lower[,2])), \n              ymax = exp(as.numeric(fcast$forecast$log_sp500$upper[,2])),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_sp500$lower[,1])), \n              ymax = exp(as.numeric(fcast$forecast$log_sp500$upper[,1])),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for S&P500\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"S&P500\"),\n         hovermode = \"x unified\")\n\n# Display plots\nfig1\n\n\n\n\n\n\nCode\nfig2\n\n\n\n\n\n\nCode\nfig3\n\n\n\n\n\n\n\n\n\n\n\n\nKR_exports, korea spread rate, usd/krw spot rate\n\ndata cleaning process\n\n\nCode\nkor_monthly &lt;- kr %&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  dplyr::select(Date,krw)\n\ntrade_monthly &lt;-exports %&gt;%\n  mutate(Date = as.Date(Date)) %&gt;%\n  mutate(Date = ceiling_date(Date, \"month\") - days(1)) %&gt;%\n  rename(export_usd = USD)%&gt;%\n  dplyr::select(Date, export_usd)\n\nusd_monthly&lt;-usd%&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  mutate(log_usd_index = log(usd_index))%&gt;%\n  dplyr::select(Date,log_usd_index)\n  \n\n\ndf2&lt;- trade_monthly%&gt;%\n  left_join(kor_monthly,by = \"Date\")%&gt;%\n  left_join(usd_monthly, by = \"Date\")\n\nstart_year_df2  &lt;- year(min(df2$Date))\nstart_month_df2 &lt;- month(min(df2$Date))\n\n\n\ntime series plotparameter selectionmodel summaryCVForecast\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df2&lt;- df2[,c(2:4)]\ndf2.ts&lt;-ts(new_df2,star=decimal_date(as.Date(\"1993-01-31\",format = \"%Y-%m-%d\")),frequency = 12)\nVARselect(df2.ts, lag.max=10, type=\"both\")\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n     3      3      1      3 \n\n$criteria\n                  1            2            3            4            5\nAIC(n) 2.637607e+01 2.633304e+01 2.623579e+01 2.626697e+01 2.628675e+01\nHQ(n)  2.643753e+01 2.643138e+01 2.637100e+01 2.643906e+01 2.649573e+01\nSC(n)  2.653099e+01 2.658092e+01 2.657662e+01 2.670075e+01 2.681350e+01\nFPE(n) 2.850902e+11 2.730883e+11 2.477867e+11 2.556470e+11 2.607768e+11\n                  6            7            8            9           10\nAIC(n) 2.625273e+01 2.626396e+01 2.627455e+01 2.630234e+01 2.627853e+01\nHQ(n)  2.649858e+01 2.654669e+01 2.659415e+01 2.665883e+01 2.667189e+01\nSC(n)  2.687243e+01 2.697662e+01 2.708016e+01 2.720091e+01 2.727005e+01\nFPE(n) 2.520816e+11 2.549671e+11 2.577307e+11 2.650602e+11 2.589011e+11\n\n\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df2, p=1, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: export_usd, krw, log_usd_index \nDeterministic variables: both \nSample size: 391 \nLog Likelihood: -6799.329 \nRoots of the characteristic polynomial:\n0.9796 0.9355 0.7926\nCall:\nVAR(y = new_df2, p = 1, type = \"both\")\n\n\nEstimation results for equation export_usd: \n=========================================== \nexport_usd = export_usd.l1 + krw.l1 + log_usd_index.l1 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1     7.980e-01  3.068e-02  26.013  &lt; 2e-16 ***\nkrw.l1           -3.069e+02  2.136e+02  -1.436   0.1517    \nlog_usd_index.l1  7.312e+05  2.977e+05   2.456   0.0145 *  \nconst            -2.881e+06  1.241e+06  -2.321   0.0208 *  \ntrend             4.377e+03  7.104e+02   6.161 1.82e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 527200 on 386 degrees of freedom\nMultiple R-Squared: 0.9563, Adjusted R-squared: 0.9558 \nF-statistic:  2111 on 4 and 386 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation krw: \n==================================== \nkrw = export_usd.l1 + krw.l1 + log_usd_index.l1 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1     1.523e-06  2.798e-06   0.544    0.587    \nkrw.l1            9.292e-01  1.949e-02  47.679   &lt;2e-16 ***\nlog_usd_index.l1  3.853e+01  2.716e+01   1.419    0.157    \nconst            -1.049e+02  1.132e+02  -0.927    0.355    \ntrend             2.101e-02  6.480e-02   0.324    0.746    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 48.09 on 386 degrees of freedom\nMultiple R-Squared: 0.9236, Adjusted R-squared: 0.9229 \nF-statistic:  1167 on 4 and 386 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_usd_index: \n============================================== \nlog_usd_index = export_usd.l1 + krw.l1 + log_usd_index.l1 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1     1.977e-09  1.269e-09   1.557   0.1202    \nkrw.l1           -7.165e-06  8.840e-06  -0.811   0.4181    \nlog_usd_index.l1  9.805e-01  1.232e-02  79.586   &lt;2e-16 ***\nconst             9.360e-02  5.136e-02   1.822   0.0692 .  \ntrend            -3.110e-05  2.939e-05  -1.058   0.2907    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.02181 on 386 degrees of freedom\nMultiple R-Squared: 0.9632, Adjusted R-squared: 0.9628 \nF-statistic:  2524 on 4 and 386 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n              export_usd        krw log_usd_index\nexport_usd     2.779e+11 -1.282e+05    -1.677e+01\nkrw           -1.282e+05  2.313e+03     3.819e-01\nlog_usd_index -1.677e+01  3.819e-01     4.758e-04\n\nCorrelation matrix of residuals:\n              export_usd       krw log_usd_index\nexport_usd      1.000000 -0.005057     -0.001458\nkrw            -0.005057  1.000000      0.364089\nlog_usd_index  -0.001458  0.364089      1.000000\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df2, p=3, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: export_usd, krw, log_usd_index \nDeterministic variables: both \nSample size: 389 \nLog Likelihood: -6721.043 \nRoots of the characteristic polynomial:\n0.9764 0.9419 0.9358 0.6103 0.6103 0.2341 0.2144 0.1315 0.1216\nCall:\nVAR(y = new_df2, p = 3, type = \"both\")\n\n\nEstimation results for equation export_usd: \n=========================================== \nexport_usd = export_usd.l1 + krw.l1 + log_usd_index.l1 + export_usd.l2 + krw.l2 + log_usd_index.l2 + export_usd.l3 + krw.l3 + log_usd_index.l3 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1     4.817e-01  4.882e-02   9.865  &lt; 2e-16 ***\nkrw.l1           -4.781e+02  5.492e+02  -0.871  0.38456    \nlog_usd_index.l1 -4.254e+05  1.209e+06  -0.352  0.72510    \nexport_usd.l2     7.103e-02  5.463e-02   1.300  0.19436    \nkrw.l2            1.596e+01  7.332e+02   0.022  0.98264    \nlog_usd_index.l2  1.891e+06  1.718e+06   1.100  0.27193    \nexport_usd.l3     3.575e-01  4.958e-02   7.211 3.05e-12 ***\nkrw.l3            2.556e+02  5.475e+02   0.467  0.64088    \nlog_usd_index.l3 -1.175e+06  1.216e+06  -0.966  0.33449    \nconst            -1.049e+06  1.163e+06  -0.902  0.36767    \ntrend             2.122e+03  7.012e+02   3.027  0.00264 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 480600 on 378 degrees of freedom\nMultiple R-Squared: 0.9641, Adjusted R-squared: 0.9632 \nF-statistic:  1016 on 10 and 378 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation krw: \n==================================== \nkrw = export_usd.l1 + krw.l1 + log_usd_index.l1 + export_usd.l2 + krw.l2 + log_usd_index.l2 + export_usd.l3 + krw.l3 + log_usd_index.l3 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1    -2.065e-06  4.880e-06  -0.423  0.67242    \nkrw.l1            8.833e-01  5.489e-02  16.092  &lt; 2e-16 ***\nlog_usd_index.l1  2.883e+02  1.208e+02   2.386  0.01752 *  \nexport_usd.l2     5.398e-06  5.460e-06   0.989  0.32348    \nkrw.l2            1.036e-01  7.329e-02   1.414  0.15822    \nlog_usd_index.l2 -4.539e+02  1.718e+02  -2.643  0.00857 ** \nexport_usd.l3    -9.176e-07  4.956e-06  -0.185  0.85320    \nkrw.l3           -5.691e-02  5.472e-02  -1.040  0.29906    \nlog_usd_index.l3  2.001e+02  1.216e+02   1.646  0.10068    \nconst            -8.750e+01  1.162e+02  -0.753  0.45209    \ntrend             8.929e-04  7.008e-02   0.013  0.98984    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 48.03 on 378 degrees of freedom\nMultiple R-Squared: 0.9241, Adjusted R-squared: 0.9221 \nF-statistic:   460 on 10 and 378 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_usd_index: \n============================================== \nlog_usd_index = export_usd.l1 + krw.l1 + log_usd_index.l1 + export_usd.l2 + krw.l2 + log_usd_index.l2 + export_usd.l3 + krw.l3 + log_usd_index.l3 + const + trend \n\n                   Estimate Std. Error t value Pr(&gt;|t|)    \nexport_usd.l1     3.779e-10  2.227e-09   0.170    0.865    \nkrw.l1           -2.035e-05  2.504e-05  -0.813    0.417    \nlog_usd_index.l1  1.048e+00  5.513e-02  19.009   &lt;2e-16 ***\nexport_usd.l2     1.232e-09  2.491e-09   0.494    0.621    \nkrw.l2            1.556e-05  3.344e-05   0.465    0.642    \nlog_usd_index.l2 -6.182e-02  7.837e-02  -0.789    0.431    \nexport_usd.l3     9.456e-10  2.261e-09   0.418    0.676    \nkrw.l3           -1.184e-06  2.497e-05  -0.047    0.962    \nlog_usd_index.l3 -9.379e-03  5.547e-02  -0.169    0.866    \nconst             1.093e-01  5.304e-02   2.061    0.040 *  \ntrend            -4.407e-05  3.198e-05  -1.378    0.169    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.02191 on 378 degrees of freedom\nMultiple R-Squared: 0.9636, Adjusted R-squared: 0.9626 \nF-statistic:  1001 on 10 and 378 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n              export_usd        krw log_usd_index\nexport_usd     2.309e+11 -2.608e+05    -2.189e+02\nkrw           -2.608e+05  2.307e+03     3.799e-01\nlog_usd_index -2.189e+02  3.799e-01     4.802e-04\n\nCorrelation matrix of residuals:\n              export_usd     krw log_usd_index\nexport_usd       1.00000 -0.0113      -0.02079\nkrw             -0.01130  1.0000       0.36091\nlog_usd_index   -0.02079  0.3609       1.00000\n\n\n\n\n\n\nCode\nn=length(df2$Date) #392\nk=98 #25% of data for training\n#n-k=294; 294/12=24.5\nrmse1 &lt;- matrix(NA, 294,3) #here 294 is n-k\nrmse2 &lt;- matrix(NA, 294,3)\nyear&lt;-c()\n# Convert data frame to time series object\nts_obj &lt;- ts(df2[, c(2:4)], start=decimal_date(as.Date(\"1993-01-31\",format = \"%Y-%m-%d\")),frequency = 12)\nst &lt;- tsp(ts_obj)[1]+(k-1)/12 \nfor(i in 1:24) #here 24 is (n-k ) / 12 = 294/12 =24.5\n{\n  \n  xtrain &lt;- window(ts_obj, end=st + i-1)\n  xtest &lt;- window(ts_obj, start=st + (i-1) + 1/12, end=st + i)\n  \n  # first model p = 1 \n  fit &lt;- vars::VAR(xtrain, p=1, type='both')\n  fcast &lt;- predict(fit, n.ahead = 12)\n  \n  fexport&lt;-fcast$fcst$export_usd\n  fkrw&lt;-fcast$fcst$krw\n  fusd&lt;-fcast$fcst$log_usd_index\n  \n  ff1&lt;-data.frame(fexport[,1],fkrw[,1],fusd[,1]) \n  year&lt;-st + (i-1) + 1/12 \n  \n  \n  ff1&lt;-ts(ff1,start=c(year,1),frequency = 12)\n  \n  a = 12*i-11 \n  b= 12*i \n \n  rmse1[c(a:b),]  &lt;-sqrt((ff1-xtest)^2)\n  \n  #second model p = 3\n  fit2 &lt;- vars::VAR(xtrain, p=3, type='both')\n  fcast2 &lt;- predict(fit2, n.ahead = 12)\n  \n  fexport2&lt;-fcast2$fcst$export_usd\n  fkrw2&lt;-fcast2$fcst$krw\n  fusd2&lt;-fcast2$fcst$log_usd_index\n  ff2&lt;-data.frame(fexport2[,1],fkrw2[,1],fusd2[,1])\n  \n  year&lt;-st + (i-1) + 1/12\n  \n  ff2&lt;-ts(ff2,start=c(year,1),frequency = 12)\n  \n  a = 12*i-11\n  b= 12*i\n  rmse2[c(a:b),]  &lt;-sqrt((ff2-xtest)^2)\n}\n\n\n\n\nCode\nmonth_index = 1:294 #monthly index\n# Create date sequence for test period (starts from observation k+1 = 99)\ntest_dates = as.Date(df2$Date[(k+1):n])\nrmse1 = data.frame(month_index,test_dates,rmse1)\nnames(rmse1) =c(\"Month\",\"Date\",\"export_usd\",\"krw\",\"log_usd_index\")\nrmse2 = data.frame(month_index,test_dates,rmse2)\nnames(rmse2) =c(\"Month\",\"Date\",\"export_usd\",\"krw\",\"log_usd_index\")\n# Combine both data frames and add a Model column\nrmse1$Model &lt;- \"VAR(1)\"\nrmse2$Model &lt;- \"VAR(3)\"\nrmse_combined &lt;- rbind(rmse1, rmse2)\n# Combine both data frames and add a Model column\nrmse1$Model &lt;- \"VAR(1)\"\nrmse2$Model &lt;- \"VAR(3)\"\nrmse_combined &lt;- rbind(rmse1, rmse2)\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = krw, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for krw\",\n    x = \"Date\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = log_usd_index, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for log_usd_index\",\n    x = \"Date\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Create the export_usd RMSE plot with a legend\nggplot(data = rmse_combined, aes(x = Date, y = export_usd, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for export_usd\",\n    x = \"Date\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Forecast 12 months ahead\nh &lt;- 36\nfcast &lt;- forecast(var1, h = h)\n\n# export_usd plot (not log-transformed, keep as is)\nfig1 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"export_usd\"], 100))), \n            y = as.numeric(tail(ts_obj[, \"export_usd\"], 100)), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$export_usd$mean)), \n            y = as.numeric(fcast$forecast$export_usd$mean), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$export_usd$mean)), \n              ymin = as.numeric(fcast$forecast$export_usd$lower[,2]), \n              ymax = as.numeric(fcast$forecast$export_usd$upper[,2]),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$export_usd$mean)), \n              ymin = as.numeric(fcast$forecast$export_usd$lower[,1]), \n              ymax = as.numeric(fcast$forecast$export_usd$upper[,1]),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(1) Forecast for export_usd\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"export_usd\"),\n         hovermode = \"x unified\")\n\nfig2 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"krw\"], 100))), \n            y = as.numeric(tail(ts_obj[, \"krw\"], 100)), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$krw$mean)), \n            y = as.numeric(fcast$forecast$krw$mean), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$krw$mean)), \n              ymin = as.numeric(fcast$forecast$krw$lower[,2]), \n              ymax = as.numeric(fcast$forecast$krw$upper[,2]),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$krw$mean)), \n              ymin = as.numeric(fcast$forecast$krw$lower[,1]), \n              ymax = as.numeric(fcast$forecast$krw$upper[,1]),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(1) Forecast for krw\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"krw\"),\n         hovermode = \"x unified\")\n\nfig3 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"log_usd_index\"], 100))), \n            y = exp(as.numeric(tail(ts_obj[, \"log_usd_index\"], 100))), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$log_usd_index$mean)), \n            y = exp(as.numeric(fcast$forecast$log_usd_index$mean)), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_usd_index$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_usd_index$lower[,2])), \n              ymax = exp(as.numeric(fcast$forecast$log_usd_index$upper[,2])),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_usd_index$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_usd_index$lower[,1])), \n              ymax = exp(as.numeric(fcast$forecast$log_usd_index$upper[,1])),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(1) Forecast for USD Index\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"USD Index\"),\n         hovermode = \"x unified\")\n\n\nfig1\n\n\n\n\n\n\nCode\nfig2\n\n\n\n\n\n\nCode\nfig3\n\n\n\n\n\n\n\n\n\n\nkorea yield spread rate ~ us yield spread rate+ us ffr+ bok rate\nrate difference & FX: USD/KRW spot rate ~ us-korea spread rate 3years+ us-korea spread rate 3years+ VIX+ dollar index\n\n\n\n\nSARIMAX model: USD/KRW spot rate ~ us-korea spread rate 3years+ us-korea spread rate 10years+ S&P500+ dollar index\n\ndata cleaning\n\n\nCode\nspread_3y_monthly &lt;- us_kr_spreads_3y%&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n    dplyr::select(Date,US_KR_3Y)\n\n\nspread_10y_monthly &lt;- us_kr_spreads_10y%&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  dplyr::select(Date,US_KR_10Y)\n\n\nsp500_monthly&lt;-sp500%&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  dplyr::select(Date,Close)%&gt;%\n  rename(sp500_close = Close)\n\nusd_monthly&lt;-usd%&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  dplyr::select(Date,usd_index)\n\nkor_monthly &lt;- kr %&gt;%\n  mutate(year_month = floor_date(Date, \"month\")) %&gt;%\n  group_by(year_month) %&gt;%\n  slice_tail(n = 1) %&gt;%\n  ungroup() %&gt;%\n  mutate(Date = ceiling_date(year_month, \"month\") - days(1))%&gt;%\n  dplyr::select(Date,krw)\n\n\ndf3&lt;- spread_3y_monthly%&gt;%\n  left_join(spread_10y_monthly,by = \"Date\")%&gt;%\n  left_join(sp500_monthly, by = \"Date\")%&gt;%\n  left_join(usd_monthly,by = \"Date\")%&gt;%\n  left_join(kor_monthly)\n\nstart_year_df3  &lt;- year(min(df3$Date))\nstart_month_df3 &lt;- month(min(df3$Date))\n\nts_krw &lt;- ts(df3$krw, \n              star=decimal_date(as.Date(\"2000-12-01\",format = \"%Y-%m-%d\")),frequency = 12)  \n\nts_log_krw &lt;- ts(log(df3$krw), \n                  star=decimal_date(as.Date(\"2000-12-01\",format = \"%Y-%m-%d\")),frequency = 12)\n\n\n\n\nmanual search utility function\n\n\nCode\nSARIMA.c &lt;- function(p_range, d_range, q_range, P_range, D_range, Q_range, data) {\n  \n  # Set seasonal period\n  s &lt;- 12\n  \n  # Initialize results storage\n  results_list &lt;- list()\n  \n  # Iterate over parameter combinations\n  for (p in p_range) {\n    for (d in d_range) {\n      for (q in q_range) {\n        for (P in P_range) {\n          for (D in D_range) {\n            for (Q in Q_range) {\n              \n              # Apply parameter constraint to avoid overfitting\n              if (p + d + q + P + D + Q &lt;= 10) {\n                tryCatch({\n                  # Fit SARIMA model\n                  model &lt;- Arima(data, order = c(p, d, q), seasonal = c(P, D, Q))\n                  \n                  # Store results\n                  results_list[[length(results_list) + 1]] &lt;- c(p, d, q, P, D, Q, model$aic, model$bic, model$aicc)\n                }, error = function(e) {\n                  # Handle errors without breaking the loop\n                  cat(\"Model failed for (p=\", p, \", d=\", d, \", q=\", q, \", P=\", P, \", D=\", D, \", Q=\", Q, \")\\n\")\n                })\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n  \n  # Convert results to a tidy data frame\n  results_df &lt;- as.data.frame(do.call(rbind, results_list))\n  colnames(results_df) &lt;- c(\"p\", \"d\", \"q\", \"P\", \"D\", \"Q\", \"AIC\", \"BIC\", \"AICc\")\n  \n  return(results_df)\n}\n\n\n\n\nlog transformation\nIn EDA and univariate section, taking log for S&P500 index and USD index was better, so it will continue to use log transformation. however, here, FX rate needs to be checked\n\n\n\n\n\n\n\n\n\nfrom the plot, log transformation don’t give dramatical change, so for this model, original value for KRW/USD spot exchange rate will be used.\n\ntime series plotauto.arimamanual searchcross-validationmodel fittingforecast\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\ndf3$log_usd_index&lt;- log(df3$usd_index)\ndf3$log_sp500_close&lt;- log(df3$sp500_close)\ndf3$l1&lt;-log(df3$US_KR_3Y) \ndf3$l2&lt;-log(df3$US_KR_10Y)\ndf3.ts&lt;- ts(df3[,c( \"US_KR_3Y\",\"US_KR_10Y\",\"log_usd_index\",\"log_sp500_close\",\"krw\")],start = c(2000,12),frequency = 12)\ny1&lt;- df3.ts[,\"krw\"]\nxreg1 &lt;- df3.ts[, !(colnames(df3.ts) %in% \"krw\")]\nfit_auto1&lt;- auto.arima(y1,xreg = xreg1)\nsummary(fit_auto1)\n\n\nSeries: y1 \nRegression with ARIMA(0,0,5)(1,0,1)[12] errors \n\nCoefficients:\n         ma1     ma2     ma3     ma4     ma5    sar1    sma1   intercept\n      1.0185  0.9192  0.8077  0.5132  0.2915  0.0587  0.1304  -3430.4807\ns.e.  0.0866  0.1075  0.0744  0.0742  0.0843  0.3159  0.3023    354.6735\n      US_KR_3Y  US_KR_10Y  log_usd_index  log_sp500_close\n      -32.8100     2.1624       962.0504          28.3890\ns.e.   12.9267    13.0775        72.4748          23.0226\n\nsigma^2 = 1189:  log likelihood = -1477.74\nAIC=2981.48   AICc=2982.76   BIC=3029.59\n\nTraining set error measures:\n                    ME     RMSE      MAE         MPE     MAPE      MASE\nTraining set 0.2861407 33.77607 24.36759 -0.08942715 2.051096 0.3106065\n                   ACF1\nTraining set 0.09697159\n\n\nCode\ncheckresiduals(fit_auto1)\n\n\n\n\n\n\n\n\n\n\n    Ljung-Box test\n\ndata:  Residuals from Regression with ARIMA(0,0,5)(1,0,1)[12] errors\nQ* = 170.72, df = 17, p-value &lt; 2.2e-16\n\nModel df: 7.   Total lags used: 24\n\n\n\n\n\n\n\nCall:\nlm(formula = krw ~ US_KR_3Y + US_KR_10Y + log_sp500_close + log_usd_index, \n    data = df3)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-143.28  -65.07  -13.86   45.71  448.57 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     -3085.90     245.24 -12.583  &lt; 2e-16 ***\nUS_KR_3Y          -64.56      10.48  -6.160 2.38e-09 ***\nUS_KR_10Y          32.00      13.99   2.288   0.0229 *  \nlog_sp500_close    92.78      14.00   6.626 1.65e-10 ***\nlog_usd_index     774.29      51.50  15.036  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 85.87 on 294 degrees of freedom\nMultiple R-squared:  0.533, Adjusted R-squared:  0.5266 \nF-statistic: 83.87 on 4 and 294 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\noutput1 &lt;- SARIMA.c(\n  p_range = 0:2, q_range = 0:2, \n  d_range = 0:1, D_range = 0:1, \n  P_range = 1, Q_range = 0:2, \n  data = res.fit1\n)\n\n\nminaic &lt;- output1[which.min(output1$AIC), ]\nminbic &lt;- output1[which.min(output1$BIC), ]\n\nprint(minaic)\n\n\n   p d q P D Q      AIC      BIC    AICc\n35 0 1 2 1 1 1 2840.916 2859.196 2841.13\n\n\nCode\nmodel_output_1 &lt;- capture.output(sarima(res.fit1, 0,1,2,1,1,1,12))\n\n\n\n\n\n\n\n\n\nCode\nmodel_output_2 &lt;- capture.output(sarima(res.fit1, 0,0,5,1,0,1,12))\n\n\n\n\n\n\n\n\n\n\n\nCoefficients: \n     Estimate     SE  t.value p.value\nma1   -0.0535 0.0595  -0.8997  0.3690\nma2   -0.1284 0.0626  -2.0522  0.0411\nsar1  -0.0710 0.0618  -1.1498  0.2512\nsma1  -1.0000 0.0596 -16.7682  0.0000\n\nsigma^2 estimated as 1012.115 on 282 degrees of freedom \n \nAIC = 9.933272  AICc = 9.93377  BIC = 9.997188 \n \n\n\nCoefficients: \n      Estimate     SE t.value p.value\nma1     1.0187 0.0687 14.8269  0.0000\nma2     0.8521 0.0901  9.4559  0.0000\nma3     0.7539 0.0670 11.2585  0.0000\nma4     0.5018 0.0750  6.6902  0.0000\nma5     0.2326 0.0656  3.5479  0.0005\nsar1   -0.1625 0.5179 -0.3137  0.7540\nsma1    0.2462 0.5044  0.4882  0.6258\nxmean   1.1730 9.4233  0.1245  0.9010\n\nsigma^2 estimated as 1233.529 on 291 degrees of freedom \n \nAIC = 10.02133  AICc = 10.02299  BIC = 10.13272 \n \n\n\n\n\n\n\nCode\nlibrary(knitr)\nlibrary(kableExtra)\n\nn &lt;- length(res.fit1)  \n\n# Calculate k as 1/3rd of the data, rounded down to the nearest multiple of 12\nk &lt;- floor(n / 3 / 12) * 12  # Example: If total length is 144, then k = 48\n\nh &lt;- 12  # Forecast horizon (predicting 12 months ahead)\n\n# Initialize matrices for RMSE\nrmse1 &lt;- matrix(NA, nrow = (n-k), ncol = h)  # RMSE for Model 1\nrmse2 &lt;- matrix(NA, nrow = (n-k), ncol = h)  # RMSE for Model 2\n\n# Define rolling start time\nst &lt;- tsp(res.fit1)[1] + (k - 2) / 12  \n\n# Walk-Forward Validation Loop\nfor (i in 1:(n-k)) {\n  # Define rolling training and test sets\n  xtrain &lt;- window(res.fit1, end = st + i / 12)  \n  xtest &lt;- window(res.fit1, start = st + (i + 1) / 12, end = st + (i + h) / 12)  # 12-step ahead test data\n  \n  fit1 &lt;- Arima(xtrain, order = c(0,1,2), seasonal = list(order = c(1,1,1), period = 12),\n                include.drift = FALSE, lambda = 0, method = \"ML\")\n  fcast1 &lt;- forecast(fit1, h = h)\n  \n  fit2 &lt;- Arima(xtrain, order = c(0,0,5), seasonal = list(order = c(1,0,1), period = 12),\n                include.drift = FALSE, lambda = 0, method = \"ML\")\n  fcast2 &lt;- forecast(fit2, h = h)\n  \n  # Compute RMSE (Root Mean Squared Error)\n  rmse1[i, 1:length(xtest)] &lt;- sqrt(mean((fcast1$mean - xtest)^2, na.rm = TRUE))\n  rmse2[i, 1:length(xtest)] &lt;- sqrt(mean((fcast2$mean - xtest)^2, na.rm = TRUE))\n}\n\n# Compute Mean RMSE Across Forecast Horizons\nrmse1_avg &lt;- colMeans(rmse1, na.rm = TRUE)\nrmse2_avg &lt;- colMeans(rmse2, na.rm = TRUE)\n\n# Create a DataFrame for Plotting\nrmse_table1 &lt;- data.frame(\n  Horizon1 = 1:h,\n  RMSE_Model1 = rmse1_avg,\n  RMSE_Model2 = rmse2_avg\n)\n\n# Display RMSE Table\nkable(rmse_table1, format = \"html\", digits = 4, caption = \"RMSE for 12-Step Forecasts\") %&gt;%\n  kable_styling(full_width = FALSE, bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\n\n\n\n\nRMSE for 12-Step Forecasts\n\n\nHorizon1\nRMSE_Model1\nRMSE_Model2\n\n\n\n\n1\n75.2885\n74.8425\n\n\n2\n75.5743\n75.1145\n\n\n3\n75.3363\n75.2164\n\n\n4\n74.7199\n75.2525\n\n\n5\n74.5120\n75.1724\n\n\n6\n74.3232\n75.1111\n\n\n7\n74.2009\n75.0476\n\n\n8\n74.2162\n74.9261\n\n\n9\n74.2647\n74.7324\n\n\n10\n74.3287\n74.5284\n\n\n11\n74.4096\n74.3075\n\n\n12\n74.3660\n74.0836\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(rmse_table1, aes(x = Horizon1)) +\n  geom_line(aes(y = RMSE_Model1, color = \"SARIMA(0,1,2)(1,1,1)[12]\"), size = 1) +\n  geom_line(aes(y = RMSE_Model2, color = \"SARIMA(0,0,5)(1,0,1)[12]\"), size = 1) +\n  labs(title = \"RMSE Comparison for 12-Step Forecasts\",\n       x = \"Forecast Horizon (Months Ahead)\",\n       y = \"Root Mean Squared Error (RMSE)\") +\n  scale_color_manual(name = \"Models\", values = c(\"red\", \"blue\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nfinal_fit1&lt;- Arima(y1,order = c(0,1,2),seasonal = list(order = c(1,1,1),period = 12),xreg = xreg1)\nsummary(final_fit1)\n\n\nSeries: y1 \nRegression with ARIMA(0,1,2)(1,1,1)[12] errors \n\nCoefficients:\n          ma1      ma2     sar1     sma1  US_KR_3Y  US_KR_10Y  log_usd_index\n      -0.1410  -0.1266  -0.0513  -1.0000  -17.3951    -9.6550       883.1751\ns.e.   0.0605   0.0659   0.0626   0.1413   11.5517    11.7263        77.1053\n      log_sp500_close\n            -219.0293\ns.e.          39.0265\n\nsigma^2 = 748.9:  log likelihood = -1368.09\nAIC=2754.19   AICc=2754.84   BIC=2787.09\n\nTraining set error measures:\n                   ME     RMSE      MAE       MPE    MAPE      MASE\nTraining set 2.461805 26.38713 19.06936 0.1743897 1.62301 0.2430716\n                     ACF1\nTraining set -0.006297849\n\n\n###auto.arima\n\n\nCode\nfit_auto1&lt;- auto.arima(y1,xreg = xreg1)\nsummary(fit_auto1)\n\n\nSeries: y1 \nRegression with ARIMA(0,0,5)(1,0,1)[12] errors \n\nCoefficients:\n         ma1     ma2     ma3     ma4     ma5    sar1    sma1   intercept\n      1.0185  0.9192  0.8077  0.5132  0.2915  0.0587  0.1304  -3430.4807\ns.e.  0.0866  0.1075  0.0744  0.0742  0.0843  0.3159  0.3023    354.6735\n      US_KR_3Y  US_KR_10Y  log_usd_index  log_sp500_close\n      -32.8100     2.1624       962.0504          28.3890\ns.e.   12.9267    13.0775        72.4748          23.0226\n\nsigma^2 = 1189:  log likelihood = -1477.74\nAIC=2981.48   AICc=2982.76   BIC=3029.59\n\nTraining set error measures:\n                    ME     RMSE      MAE         MPE     MAPE      MASE\nTraining set 0.2861407 33.77607 24.36759 -0.08942715 2.051096 0.3106065\n                   ACF1\nTraining set 0.09697159"
  },
  {
    "objectID": "ts/multi.html#equity-sp500-vix-us_yield_spreadkospi-index",
    "href": "ts/multi.html#equity-sp500-vix-us_yield_spreadkospi-index",
    "title": "Multivariate TS Models(ARIMAX/SARIMAX/VAR)",
    "section": "equity: s&p500, vix, us_yield_spread,KOSPI index",
    "text": "equity: s&p500, vix, us_yield_spread,KOSPI index\n\ntime series plotparameter selectionmodel summaryCVforecast\n\n\n\n\nCode\nlibrary(dplyr)\ndf1 &lt;- us_spreads %&gt;%\n   left_join(sp500, by = \"Date\") %&gt;%\n   left_join(kospi, by = \"Date\")%&gt;%\n   dplyr::select(Date, us_spread, close_sp500 = Close.x , close_kospi = Close.y)%&gt;%\n   arrange(Date) %&gt;%\n   fill(close_sp500,close_kospi, .direction = \"down\")\n \ndf1$log_kospi&lt;- log(df1$close_kospi)\ndf1$log_sp500&lt;- log(df1$close_sp500)\n\n\n start_year_df1  &lt;- year(min(df1$Date))\n start_month_df1 &lt;- month(min(df1$Date))\n\n\np1 &lt;- plot_ly(df1, x = ~Date, y = ~us_spread, type = 'scatter', mode = 'lines',\n              name = \"U.S Spread Rate\") %&gt;%\n  layout(yaxis = list(title = \"U.S Spread Rate\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\np2 &lt;- plot_ly(df1, x = ~Date, y = ~log_sp500, type = 'scatter', mode = 'lines',\n              name = \"S&P500 Index(log)\") %&gt;%\n  layout(yaxis = list(title = \"S&P500 Index(log)\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\np3 &lt;- plot_ly(df1, x = ~Date, y = ~log_kospi, type = 'scatter', mode = 'lines',\n              name = \"KOSPI Index(log)\") %&gt;%\n  layout(yaxis = list(title = \"KOSPI Index(log)\", titlefont = list(size = 14), tickfont = list(size = 12)))\n\nsubplot(p1, p2, p3, nrows = 3, shareX = TRUE, titleX = TRUE) %&gt;%\n  layout(title = list(text = \"Equities:KOSPI index, S&P 500 index, U.S T-bond spread rate\", font = list(size = 18)),\n         margin = list(l = 70, r = 40, t = 60, b = 40))\n\n\n\n\n\n\n\n\n\n\nCode\nnew_df1&lt;- df1[,c(2,5,6)]\ndf1.ts&lt;-ts(new_df1,star=decimal_date(as.Date(\"2001-12-01\",format = \"%Y-%m-%d\")),frequency = 252)\nVARselect(df1.ts, lag.max=10, type=\"both\")\n\n\n$selection\nAIC(n)  HQ(n)  SC(n) FPE(n) \n    10      5      2     10 \n\n$criteria\n                   1             2             3             4             5\nAIC(n) -2.419658e+01 -2.436948e+01 -2.437841e+01 -2.438541e+01 -2.438900e+01\nHQ(n)  -2.419068e+01 -2.436005e+01 -2.436544e+01 -2.436890e+01 -2.436895e+01\nSC(n)  -2.417962e+01 -2.434234e+01 -2.434109e+01 -2.433791e+01 -2.433132e+01\nFPE(n)  3.101405e-11  2.608965e-11  2.585770e-11  2.567740e-11  2.558543e-11\n                   6             7             8             9            10\nAIC(n) -2.439247e+01 -2.439309e+01 -2.439656e+01 -2.440048e+01 -2.440168e+01\nHQ(n)  -2.436889e+01 -2.436597e+01 -2.436590e+01 -2.436628e+01 -2.436394e+01\nSC(n)  -2.432461e+01 -2.431505e+01 -2.430834e+01 -2.430208e+01 -2.429310e+01\nFPE(n)  2.549667e-11  2.548083e-11  2.539261e-11  2.529342e-11  2.526311e-11\n\n\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=2, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5918 \nLog Likelihood: 46927.097 \nRoots of the characteristic polynomial:\n0.9987 0.9979 0.9954 0.2162 0.0273 0.0273\nCall:\nVAR(y = new_df1, p = 2, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  1.005e+00  1.302e-02  77.209   &lt;2e-16 ***\nlog_kospi.l1  4.318e-02  3.263e-02   1.324    0.186    \nlog_sp500.l1  5.690e-02  3.593e-02   1.583    0.113    \nus_spread.l2 -7.440e-03  1.302e-02  -0.572    0.568    \nlog_kospi.l2 -4.234e-02  3.264e-02  -1.297    0.195    \nlog_sp500.l2 -5.388e-02  3.591e-02  -1.501    0.134    \nconst        -2.991e-02  2.686e-02  -1.114    0.265    \ntrend        -4.247e-07  1.078e-06  -0.394    0.694    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03353 on 5910 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 4.428e+05 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  4.210e-03  4.990e-03   0.844   0.3989    \nlog_kospi.l1  9.266e-01  1.250e-02  74.106  &lt; 2e-16 ***\nlog_sp500.l1  3.906e-01  1.377e-02  28.365  &lt; 2e-16 ***\nus_spread.l2 -4.170e-03  4.989e-03  -0.836   0.4032    \nlog_kospi.l2  7.104e-02  1.251e-02   5.679 1.42e-08 ***\nlog_sp500.l2 -3.907e-01  1.376e-02 -28.390  &lt; 2e-16 ***\nconst         1.698e-02  1.029e-02   1.650   0.0991 .  \ntrend         4.458e-07  4.131e-07   1.079   0.2805    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01285 on 5910 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 1.081e+06 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1 -7.316e-03  4.799e-03  -1.524 0.127492    \nlog_kospi.l1  3.228e-02  1.203e-02   2.684 0.007286 ** \nlog_sp500.l1  8.753e-01  1.324e-02  66.083  &lt; 2e-16 ***\nus_spread.l2  7.526e-03  4.798e-03   1.569 0.116796    \nlog_kospi.l2 -3.438e-02  1.203e-02  -2.858 0.004284 ** \nlog_sp500.l2  1.215e-01  1.324e-02   9.183  &lt; 2e-16 ***\nconst         3.540e-02  9.900e-03   3.576 0.000352 ***\ntrend         1.609e-06  3.973e-07   4.049  5.2e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01236 on 5910 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 1.748e+06 on 7 and 5910 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread log_kospi  log_sp500\nus_spread  1.124e-03 1.530e-06 -1.898e-05\nlog_kospi  1.530e-06 1.651e-04  4.392e-05\nlog_sp500 -1.898e-05 4.392e-05  1.527e-04\n\nCorrelation matrix of residuals:\n          us_spread log_kospi log_sp500\nus_spread  1.000000  0.003551  -0.04582\nlog_kospi  0.003551  1.000000   0.27658\nlog_sp500 -0.045820  0.276579   1.00000\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=5, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5915 \nLog Likelihood: 46994.576 \nRoots of the characteristic polynomial:\n0.9989 0.9983 0.9951 0.5204 0.5204 0.5144 0.5144 0.4234 0.4111 0.4111 0.3816 0.3816 0.373 0.373 0.2981\nCall:\nVAR(y = new_df1, p = 5, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  1.002e+00  1.301e-02  77.017  &lt; 2e-16 ***\nlog_kospi.l1  1.256e-02  3.563e-02   0.352 0.724478    \nlog_sp500.l1  6.579e-02  3.675e-02   1.790 0.073477 .  \nus_spread.l2  8.197e-04  1.843e-02   0.044 0.964530    \nlog_kospi.l2 -3.401e-02  4.707e-02  -0.723 0.469980    \nlog_sp500.l2 -9.580e-03  4.836e-02  -0.198 0.842991    \nus_spread.l3 -2.020e-02  1.843e-02  -1.096 0.273182    \nlog_kospi.l3  2.201e-02  4.719e-02   0.466 0.640900    \nlog_sp500.l3  6.182e-02  4.972e-02   1.243 0.213783    \nus_spread.l4 -1.204e-02  1.843e-02  -0.653 0.513772    \nlog_kospi.l4  2.331e-02  4.615e-02   0.505 0.613522    \nlog_sp500.l4  2.283e-02  4.924e-02   0.464 0.642863    \nus_spread.l5  2.717e-02  1.300e-02   2.089 0.036755 *  \nlog_kospi.l5 -2.352e-02  3.276e-02  -0.718 0.472758    \nlog_sp500.l5 -1.388e-01  3.949e-02  -3.515 0.000443 ***\nconst        -1.963e-02  2.694e-02  -0.729 0.466262    \ntrend        -1.036e-07  1.081e-06  -0.096 0.923694    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03347 on 5898 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 1.942e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  3.449e-03  4.950e-03   0.697   0.4860    \nlog_kospi.l1  8.749e-01  1.355e-02  64.561  &lt; 2e-16 ***\nlog_sp500.l1  4.162e-01  1.398e-02  29.779  &lt; 2e-16 ***\nus_spread.l2 -9.057e-03  7.010e-03  -1.292   0.1964    \nlog_kospi.l2  7.212e-02  1.790e-02   4.028 5.69e-05 ***\nlog_sp500.l2 -2.779e-01  1.839e-02 -15.106  &lt; 2e-16 ***\nus_spread.l3  2.893e-03  7.010e-03   0.413   0.6798    \nlog_kospi.l3  2.295e-02  1.795e-02   1.279   0.2010    \nlog_sp500.l3 -2.757e-02  1.891e-02  -1.458   0.1449    \nus_spread.l4  2.902e-03  7.011e-03   0.414   0.6790    \nlog_kospi.l4  1.520e-02  1.755e-02   0.866   0.3866    \nlog_sp500.l4 -8.148e-02  1.873e-02  -4.351 1.38e-05 ***\nus_spread.l5  2.195e-05  4.946e-03   0.004   0.9965    \nlog_kospi.l5  1.240e-02  1.246e-02   0.995   0.3197    \nlog_sp500.l5 -2.974e-02  1.502e-02  -1.980   0.0477 *  \nconst         2.053e-02  1.024e-02   2.004   0.0451 *  \ntrend         4.817e-07  4.112e-07   1.172   0.2414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01273 on 5898 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 4.801e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + const + trend \n\n               Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1 -6.714e-03  4.799e-03  -1.399 0.161845    \nlog_kospi.l1  3.661e-02  1.314e-02   2.787 0.005344 ** \nlog_sp500.l1  8.733e-01  1.355e-02  64.448  &lt; 2e-16 ***\nus_spread.l2  3.149e-03  6.797e-03   0.463 0.643122    \nlog_kospi.l2 -4.948e-02  1.736e-02  -2.851 0.004378 ** \nlog_sp500.l2  1.165e-01  1.783e-02   6.533 7.00e-11 ***\nus_spread.l3  3.961e-03  6.796e-03   0.583 0.560010    \nlog_kospi.l3  1.150e-02  1.740e-02   0.661 0.508860    \nlog_sp500.l3  2.171e-02  1.833e-02   1.184 0.236461    \nus_spread.l4  1.208e-02  6.797e-03   1.777 0.075545 .  \nlog_kospi.l4  1.366e-02  1.702e-02   0.803 0.422232    \nlog_sp500.l4 -4.602e-02  1.816e-02  -2.535 0.011276 *  \nus_spread.l5 -1.230e-02  4.795e-03  -2.564 0.010364 *  \nlog_kospi.l5 -1.436e-02  1.208e-02  -1.189 0.234606    \nlog_sp500.l5  3.140e-02  1.456e-02   2.156 0.031122 *  \nconst         3.451e-02  9.932e-03   3.474 0.000516 ***\ntrend         1.580e-06  3.986e-07   3.963 7.49e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01234 on 5898 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 7.667e+05 on 16 and 5898 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread  log_kospi  log_sp500\nus_spread  1.120e-03 -4.196e-07 -1.812e-05\nlog_kospi -4.196e-07  1.620e-04  4.394e-05\nlog_sp500 -1.812e-05  4.394e-05  1.523e-04\n\nCorrelation matrix of residuals:\n           us_spread  log_kospi log_sp500\nus_spread  1.0000000 -0.0009848  -0.04386\nlog_kospi -0.0009848  1.0000000   0.27970\nlog_sp500 -0.0438603  0.2797035   1.00000\n\n\n\n\nCode\nsummary(fit &lt;- VAR(new_df1, p=10, type=\"both\"))\n\n\n\nVAR Estimation Results:\n========================= \nEndogenous variables: us_spread, log_kospi, log_sp500 \nDeterministic variables: both \nSample size: 5910 \nLog Likelihood: 47045.173 \nRoots of the characteristic polynomial:\n0.999 0.9984 0.9951 0.7704 0.7704 0.7486 0.7486 0.7463 0.7463 0.7041 0.7041 0.6959 0.6895 0.6895 0.6807 0.6807 0.6722 0.6554 0.6554 0.6546 0.6546 0.6301 0.6301 0.601 0.601 0.5982 0.5982 0.4709 0.4588 0.3093\nCall:\nVAR(y = new_df1, p = 10, type = \"both\")\n\n\nEstimation results for equation us_spread: \n========================================== \nus_spread = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1   1.002e+00  1.305e-02  76.749  &lt; 2e-16 ***\nlog_kospi.l1   3.737e-03  3.569e-02   0.105 0.916600    \nlog_sp500.l1   6.888e-02  3.692e-02   1.866 0.062132 .  \nus_spread.l2   1.230e-03  1.846e-02   0.067 0.946885    \nlog_kospi.l2  -3.245e-02  4.708e-02  -0.689 0.490682    \nlog_sp500.l2   6.665e-05  4.857e-02   0.001 0.998905    \nus_spread.l3  -1.983e-02  1.843e-02  -1.076 0.282071    \nlog_kospi.l3   2.075e-02  4.720e-02   0.440 0.660182    \nlog_sp500.l3   5.134e-02  4.989e-02   1.029 0.303429    \nus_spread.l4  -1.334e-02  1.841e-02  -0.725 0.468652    \nlog_kospi.l4  -7.511e-04  4.720e-02  -0.016 0.987305    \nlog_sp500.l4   4.288e-02  4.984e-02   0.860 0.389668    \nus_spread.l5   9.839e-04  1.841e-02   0.053 0.957376    \nlog_kospi.l5  -6.118e-02  4.718e-02  -1.297 0.194734    \nlog_sp500.l5  -6.796e-02  4.989e-02  -1.362 0.173150    \nus_spread.l6   1.159e-02  1.840e-02   0.629 0.529055    \nlog_kospi.l6   1.586e-01  4.722e-02   3.359 0.000786 ***\nlog_sp500.l6  -6.364e-02  4.981e-02  -1.278 0.201468    \nus_spread.l7   2.156e-02  1.841e-02   1.171 0.241726    \nlog_kospi.l7  -1.830e-02  4.724e-02  -0.387 0.698491    \nlog_sp500.l7  -1.358e-01  4.980e-02  -2.727 0.006407 ** \nus_spread.l8   3.135e-03  1.842e-02   0.170 0.864816    \nlog_kospi.l8  -5.057e-02  4.724e-02  -1.071 0.284413    \nlog_sp500.l8   1.883e-01  4.983e-02   3.778 0.000159 ***\nus_spread.l9  -1.267e-02  1.844e-02  -0.687 0.492146    \nlog_kospi.l9  -7.425e-02  4.621e-02  -1.607 0.108167    \nlog_sp500.l9  -9.591e-02  4.943e-02  -1.940 0.052404 .  \nus_spread.l10  4.044e-03  1.302e-02   0.311 0.756052    \nlog_kospi.l10  5.440e-02  3.283e-02   1.657 0.097623 .  \nlog_sp500.l10  1.349e-02  3.967e-02   0.340 0.733836    \nconst         -1.445e-02  2.705e-02  -0.534 0.593179    \ntrend          3.707e-08  1.086e-06   0.034 0.972763    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.03338 on 5878 degrees of freedom\nMultiple R-Squared: 0.9981, Adjusted R-squared: 0.9981 \nF-statistic: 1.007e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_kospi: \n========================================== \nlog_kospi = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1   3.823e-03  4.961e-03   0.770  0.44105    \nlog_kospi.l1   8.713e-01  1.357e-02  64.213  &lt; 2e-16 ***\nlog_sp500.l1   4.219e-01  1.404e-02  30.057  &lt; 2e-16 ***\nus_spread.l2  -1.007e-02  7.018e-03  -1.435  0.15138    \nlog_kospi.l2   7.196e-02  1.790e-02   4.021 5.88e-05 ***\nlog_sp500.l2  -2.801e-01  1.847e-02 -15.166  &lt; 2e-16 ***\nus_spread.l3   2.181e-03  7.007e-03   0.311  0.75564    \nlog_kospi.l3   2.189e-02  1.794e-02   1.220  0.22256    \nlog_sp500.l3  -2.711e-02  1.897e-02  -1.429  0.15294    \nus_spread.l4   3.345e-03  7.000e-03   0.478  0.63279    \nlog_kospi.l4   6.615e-03  1.795e-02   0.369  0.71247    \nlog_sp500.l4  -7.452e-02  1.895e-02  -3.932 8.53e-05 ***\nus_spread.l5  -8.468e-03  6.999e-03  -1.210  0.22639    \nlog_kospi.l5  -1.493e-02  1.794e-02  -0.832  0.40531    \nlog_sp500.l5  -1.364e-02  1.897e-02  -0.719  0.47203    \nus_spread.l6   1.404e-02  6.997e-03   2.007  0.04483 *  \nlog_kospi.l6   4.627e-02  1.795e-02   2.577  0.00998 ** \nlog_sp500.l6  -1.438e-02  1.894e-02  -0.759  0.44783    \nus_spread.l7  -2.637e-03  7.000e-03  -0.377  0.70636    \nlog_kospi.l7  -1.601e-02  1.796e-02  -0.892  0.37269    \nlog_sp500.l7   3.496e-02  1.893e-02   1.846  0.06490 .  \nus_spread.l8   6.284e-03  7.002e-03   0.898  0.36947    \nlog_kospi.l8  -1.374e-02  1.796e-02  -0.765  0.44418    \nlog_sp500.l8   1.423e-02  1.895e-02   0.751  0.45251    \nus_spread.l9  -1.457e-02  7.010e-03  -2.078  0.03772 *  \nlog_kospi.l9   4.660e-02  1.757e-02   2.652  0.00802 ** \nlog_sp500.l9  -3.879e-02  1.880e-02  -2.064  0.03907 *  \nus_spread.l10  6.351e-03  4.949e-03   1.283  0.19941    \nlog_kospi.l10 -2.255e-02  1.248e-02  -1.806  0.07090 .  \nlog_sp500.l10 -2.325e-02  1.508e-02  -1.541  0.12326    \nconst          2.347e-02  1.029e-02   2.282  0.02253 *  \ntrend          5.469e-07  4.128e-07   1.325  0.18527    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01269 on 5878 degrees of freedom\nMultiple R-Squared: 0.9992, Adjusted R-squared: 0.9992 \nF-statistic: 2.479e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\nEstimation results for equation log_sp500: \n========================================== \nlog_sp500 = us_spread.l1 + log_kospi.l1 + log_sp500.l1 + us_spread.l2 + log_kospi.l2 + log_sp500.l2 + us_spread.l3 + log_kospi.l3 + log_sp500.l3 + us_spread.l4 + log_kospi.l4 + log_sp500.l4 + us_spread.l5 + log_kospi.l5 + log_sp500.l5 + us_spread.l6 + log_kospi.l6 + log_sp500.l6 + us_spread.l7 + log_kospi.l7 + log_sp500.l7 + us_spread.l8 + log_kospi.l8 + log_sp500.l8 + us_spread.l9 + log_kospi.l9 + log_sp500.l9 + us_spread.l10 + log_kospi.l10 + log_sp500.l10 + const + trend \n\n                Estimate Std. Error t value Pr(&gt;|t|)    \nus_spread.l1  -5.799e-03  4.795e-03  -1.209 0.226579    \nlog_kospi.l1   3.762e-02  1.311e-02   2.868 0.004143 ** \nlog_sp500.l1   8.775e-01  1.357e-02  64.678  &lt; 2e-16 ***\nus_spread.l2   3.384e-03  6.783e-03   0.499 0.617871    \nlog_kospi.l2  -5.056e-02  1.730e-02  -2.922 0.003486 ** \nlog_sp500.l2   1.102e-01  1.785e-02   6.173 7.13e-10 ***\nus_spread.l3   1.698e-03  6.773e-03   0.251 0.802102    \nlog_kospi.l3   1.404e-02  1.734e-02   0.809 0.418430    \nlog_sp500.l3   2.354e-02  1.833e-02   1.284 0.199261    \nus_spread.l4   1.370e-02  6.766e-03   2.025 0.042940 *  \nlog_kospi.l4   1.411e-02  1.735e-02   0.814 0.415946    \nlog_sp500.l4  -4.545e-02  1.832e-02  -2.481 0.013127 *  \nus_spread.l5  -7.747e-03  6.765e-03  -1.145 0.252170    \nlog_kospi.l5  -5.645e-02  1.734e-02  -3.256 0.001136 ** \nlog_sp500.l5   1.783e-02  1.833e-02   0.973 0.330697    \nus_spread.l6  -9.871e-04  6.763e-03  -0.146 0.883962    \nlog_kospi.l6   3.333e-02  1.735e-02   1.921 0.054797 .  \nlog_sp500.l6  -1.365e-02  1.831e-02  -0.746 0.455959    \nus_spread.l7  -1.439e-02  6.766e-03  -2.127 0.033500 *  \nlog_kospi.l7  -1.557e-02  1.736e-02  -0.897 0.369785    \nlog_sp500.l7   8.217e-02  1.830e-02   4.490 7.26e-06 ***\nus_spread.l8   2.489e-02  6.768e-03   3.678 0.000237 ***\nlog_kospi.l8  -2.296e-02  1.736e-02  -1.323 0.186001    \nlog_sp500.l8  -4.501e-02  1.831e-02  -2.458 0.014006 *  \nus_spread.l9  -1.923e-02  6.775e-03  -2.838 0.004551 ** \nlog_kospi.l9   8.825e-02  1.698e-02   5.197 2.09e-07 ***\nlog_sp500.l9   4.684e-03  1.817e-02   0.258 0.796531    \nus_spread.l10  4.649e-03  4.783e-03   0.972 0.331154    \nlog_kospi.l10 -4.380e-02  1.207e-02  -3.630 0.000286 ***\nlog_sp500.l10 -1.467e-02  1.458e-02  -1.006 0.314295    \nconst          3.262e-02  9.941e-03   3.281 0.001040 ** \ntrend          1.486e-06  3.990e-07   3.724 0.000198 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nResidual standard error: 0.01227 on 5878 degrees of freedom\nMultiple R-Squared: 0.9995, Adjusted R-squared: 0.9995 \nF-statistic: 4.005e+05 on 31 and 5878 DF,  p-value: &lt; 2.2e-16 \n\n\n\nCovariance matrix of residuals:\n           us_spread  log_kospi  log_sp500\nus_spread  1.114e-03 -1.219e-06 -1.667e-05\nlog_kospi -1.219e-06  1.611e-04  4.338e-05\nlog_sp500 -1.667e-05  4.338e-05  1.505e-04\n\nCorrelation matrix of residuals:\n          us_spread log_kospi log_sp500\nus_spread  1.000000 -0.002877  -0.04071\nlog_kospi -0.002877  1.000000   0.27864\nlog_sp500 -0.040713  0.278642   1.00000\n\n\n\n\n\n\nCode\nn=length(df1$log_sp500) \nk=1480 #1480\n#n-k=4440; 4440/252=17.619\nrmse1 &lt;- matrix(NA, 4440,3) #here 4440 is n-k\nrmse2 &lt;- matrix(NA, 4440,3)\nrmse3 &lt;- matrix(NA,4440,3) #here n-k / 252 = 4440/252 =17.619\nyear&lt;-c()\nts_obj &lt;- ts(df1[, c(2,5,6)], start=decimal_date(as.Date(\"2000-12-18\",format = \"%Y-%m-%d\")),frequency = 252)\nst &lt;- tsp(ts_obj)[1]+(k-1)/252 \nfor(i in 1:17) #here 17 is (n-k ) / 252 = 4440/252 =17.619\n{\n  \n  xtrain &lt;- window(ts_obj, end=st + i-1)\n  xtest &lt;- window(ts_obj, start=st + (i-1) + 1/252, end=st + i)\n  \n  # first model p = 2 \n  fit &lt;- vars::VAR(xtrain, p=2, type='both')\n  fcast &lt;- predict(fit, n.ahead = 252)\n  \n  fspread&lt;-fcast$fcst$us_spread\n  fkospi&lt;-fcast$fcst$log_kospi\n  fsp&lt;-fcast$fcst$log_sp500\n  \n  ff1&lt;-data.frame(fspread[,1],fkospi[,1],fsp[,1]) \n  year&lt;-st + (i-1) + 1/252 \n  \n  \n  ff1&lt;-ts(ff1,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251 \n  b= 252*i \n \n  rmse1[c(a:b),]  &lt;-sqrt((ff1-xtest)^2)\n  \n  #second model p = 5\n  fit2 &lt;- vars::VAR(xtrain, p=5, type='both')\n  fcast2 &lt;- predict(fit2, n.ahead = 252)\n  \n  fspread2&lt;-fcast2$fcst$us_spread\n  fkospi2&lt;-fcast2$fcst$log_kospi\n  fsp2&lt;-fcast2$fcst$log_sp500\n  ff2&lt;-data.frame(fspread2[,1],fkospi2[,1],fsp2[,1])\n  \n  year&lt;-st + (i-1) + 1/252\n  \n  ff2&lt;-ts(ff2,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251\n  b= 252*i\n  rmse2[c(a:b),]  &lt;-sqrt((ff2-xtest)^2)\n  \n  #third model p = 10\n  fit3 &lt;- vars::VAR(xtrain, p=10, type='both')\n  fcast3 &lt;- predict(fit3, n.ahead = 252)\n  \n  fspread3&lt;-fcast3$fcst$us_spread\n  fkospi3&lt;-fcast3$fcst$log_kospi\n  fsp3&lt;-fcast3$fcst$log_sp500\n  ff3&lt;-data.frame(fspread3[,1],fkospi3[,1],fsp3[,1])\n  \n  year&lt;-st + (i-1) + 1/252\n  \n  ff3&lt;-ts(ff3,start=c(year,1),frequency = 252)\n  \n  a = 252*i-251\n  b= 252*i\n  rmse3[c(a:b),]  &lt;-sqrt((ff3-xtest)^2)\n}\n\n\n\n\nCode\nday_index = 1:4440\ndates1 = as.Date(df1$Date[(k+1):n])\nrmse1 = data.frame(day_index,dates1,rmse1)\nnames(rmse1) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse2 = data.frame(day_index,dates1,rmse2)\nnames(rmse2) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse3 = data.frame(day_index,dates1,rmse3)\nnames(rmse3) =c(\"Day\",\"Date\",\"log_kospi\",\"log_sp500\",\"us_spread\")\nrmse1$Model &lt;- \"VAR(2)\"\nrmse2$Model &lt;- \"VAR(5)\"\nrmse3$Model &lt;- \"VAR(10)\"\nrmse_combined &lt;- rbind(rmse1, rmse2, rmse3)\nrmse1$Model &lt;- \"VAR(2)\"\nrmse2$Model &lt;- \"VAR(5)\"\nrmse3$Model &lt;- \"VAR(10)\"\nrmse_combined &lt;- rbind(rmse1, rmse2, rmse3)\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = log_kospi, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for log_kospi\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = log_sp500, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for log_sp500\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggplot(data = rmse_combined, aes(x = Date, y = us_spread, color = Model)) + \n  geom_line() +\n  labs(\n    title = \"CV RMSE for us_spread\",\n    x = \"Day\",\n    y = \"RMSE\",\n    color = \"Model\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nlibrary(vars)\nlibrary(forecast)\nlibrary(plotly)\n\n# Fit VAR(5) on full data\nvar5 &lt;- VAR(ts_obj, p = 5, type = \"both\")\n\n# Forecast 252 days ahead\nh &lt;- 504\nfcast &lt;- forecast(var5, h = h)\n\n# us_spread plot (not log-transformed, keep as is)\nfig1 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"us_spread\"], 2500))), \n            y = as.numeric(tail(ts_obj[, \"us_spread\"], 2500)), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n            y = as.numeric(fcast$forecast$us_spread$mean), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n              ymin = as.numeric(fcast$forecast$us_spread$lower[,2]), \n              ymax = as.numeric(fcast$forecast$us_spread$upper[,2]),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$us_spread$mean)), \n              ymin = as.numeric(fcast$forecast$us_spread$lower[,1]), \n              ymax = as.numeric(fcast$forecast$us_spread$upper[,1]),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for us_spread\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"us_spread\"),\n         hovermode = \"x unified\")\n\n# KOSPI plot (transform back from log to original scale)\nfig2 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"log_kospi\"], 2500))), \n            y = exp(as.numeric(tail(ts_obj[, \"log_kospi\"], 2500))), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n            y = exp(as.numeric(fcast$forecast$log_kospi$mean)), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_kospi$lower[,2])), \n              ymax = exp(as.numeric(fcast$forecast$log_kospi$upper[,2])),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_kospi$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_kospi$lower[,1])), \n              ymax = exp(as.numeric(fcast$forecast$log_kospi$upper[,1])),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for KOSPI\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"KOSPI\"),\n         hovermode = \"x unified\")\n\n# S&P500 plot (transform back from log to original scale)\nfig3 &lt;- plot_ly() %&gt;%\n  add_lines(x = as.numeric(time(tail(ts_obj[, \"log_sp500\"], 2500))), \n            y = exp(as.numeric(tail(ts_obj[, \"log_sp500\"], 2500))), \n            name = \"Historical\", line = list(color = \"black\")) %&gt;%\n  add_lines(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n            y = exp(as.numeric(fcast$forecast$log_sp500$mean)), \n            name = \"Forecast\", line = list(color = \"blue\", width = 2)) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_sp500$lower[,2])), \n              ymax = exp(as.numeric(fcast$forecast$log_sp500$upper[,2])),\n              name = \"95% CI\", fillcolor = \"rgba(0,100,255,0.2)\", \n              line = list(color = \"transparent\")) %&gt;%\n  add_ribbons(x = as.numeric(time(fcast$forecast$log_sp500$mean)), \n              ymin = exp(as.numeric(fcast$forecast$log_sp500$lower[,1])), \n              ymax = exp(as.numeric(fcast$forecast$log_sp500$upper[,1])),\n              name = \"80% CI\", fillcolor = \"rgba(0,100,255,0.4)\", \n              line = list(color = \"transparent\")) %&gt;%\n  layout(title = \"VAR(5) Forecast for S&P500\",\n         xaxis = list(title = \"Year\"),\n         yaxis = list(title = \"S&P500\"),\n         hovermode = \"x unified\")\n\n# Display plots\nfig1\n\n\n\n\n\n\nCode\nfig2\n\n\n\n\n\n\nCode\nfig3"
  }
]